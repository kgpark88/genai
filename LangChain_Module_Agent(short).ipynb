{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMUrWfETCvXg"
   },
   "source": [
    "# LangChain 모듈 - Agent\n",
    "Agent의 핵심 아이디어는 언어 모델을 사용하여 수행할 일련의 작업을 선택하는 것입니다.  \n",
    "Chain에서는 일련의 작업순서를 코드에 하드코딩 합니다.   \n",
    "하지만, Agent에서는 언어모델이 추론엔진으로 사용되어, 어떤 작업을 어떤 순서로 수행할지 결정합니다.\n",
    "  \n",
    "- Code 출처 : https://python.langchain.com/docs/modules/agents/\n",
    "- 수정사항 : 설명과 프롬프트 내용을 한글로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: langchain-openai in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (0.0.6)\n",
      "Collecting langchain-community==0.0.19\n",
      "  Using cached langchain_community-0.0.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-community==0.0.19) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-community==0.0.19) (2.0.16)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-community==0.0.19) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-community==0.0.19) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.21 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-community==0.0.19) (0.1.25)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain-community==0.0.19)\n",
      "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-community==0.0.19) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-community==0.0.19) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-community==0.0.19) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (1.33)\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached langchain-0.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (2.6.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-openai) (1.12.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.19) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.19) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.19) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (4.3.0)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.2,>=0.1.21 (from langchain-community==0.0.19)\n",
      "  Using cached langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Using cached langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain-community==0.0.19)\n",
      "  Using cached langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-core<0.2,>=0.1.21->langchain-community==0.0.19) (23.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.19) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.19) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.19) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.19) (2.0.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.6.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.19) (1.0.0)\n",
      "Using cached langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\n",
      "Using cached langchain-0.1.6-py3-none-any.whl (811 kB)\n",
      "Using cached langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
      "Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: langsmith, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.5\n",
      "    Uninstalling langsmith-0.1.5:\n",
      "      Successfully uninstalled langsmith-0.1.5\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.25\n",
      "    Uninstalling langchain-core-0.1.25:\n",
      "      Successfully uninstalled langchain-core-0.1.25\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.21\n",
      "    Uninstalling langchain-community-0.0.21:\n",
      "      Successfully uninstalled langchain-community-0.0.21\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.8\n",
      "    Uninstalling langchain-0.1.8:\n",
      "      Successfully uninstalled langchain-0.1.8\n",
      "Successfully installed langchain-0.1.6 langchain-community-0.0.19 langchain-core-0.1.23 langsmith-0.0.87\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai langchain-community==0.0.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: LangSmith\n",
    "Agent는 사용자에게 표시되는 출력을 반환하기 전에 입력에 따라 자체 결정된 일련의 단계를 수행합니다.      \n",
    "이로 인해 이러한 시스템을 디버깅하는 것이 특히 까다로워지고, 관찰 가능성이 특히 중요해집니다.    \n",
    "LangSmith는 이러한 경우에 특히 유용합니다.   \n",
    "LangChain으로 빌드할 때, 모든 단계는 LangSmith에서 자동으로 추적됩니다.   \n",
    "LangSmith 설정은 다음 환경변수로 합니다.  \n",
    "LangChain API Key :  https://smith.langchain.com/  \n",
    "- export LANGCHAIN_TRACING_V2=\"true\"  \n",
    "- export LANGCHAIN_API_KEY=\"<your-api-key>  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your OpenAI API key if not set as env var>\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"<your LangChain API key if not set as env var>\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tavily : https://app.tavily.com/\n",
    "- LangChain에 Tavily 검색 엔진을 도구로 쉽게 사용할 수 있도록 내장된 도구를 가지고 있습니다.\n",
    "- Tavily API 키가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TAVILY_API_KEY\"] = \"<your Tavily API key if not set as env var>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"Weather in San Francisco is {'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1708496329, 'localtime': '2024-02-20 22:18'}, 'current': {'last_updated_epoch': 1708496100, 'last_updated': '2024-02-20 22:15', 'temp_c': 11.1, 'temp_f': 52.0, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 2.2, 'wind_kph': 3.6, 'wind_degree': 10, 'wind_dir': 'N', 'pressure_mb': 1019.0, 'pressure_in': 30.09, 'precip_mm': 0.16, 'precip_in': 0.01, 'humidity': 93, 'cloud': 75, 'feelslike_c': 9.9, 'feelslike_f': 49.9, 'vis_km': 14.0, 'vis_miles': 8.0, 'uv': 1.0, 'gust_mph': 10.6, 'gust_kph': 17.0}}\"},\n",
       " {'url': 'https://www.wunderground.com/hourly/us/ca/san-francisco/94117/date/2024-2-21',\n",
       "  'content': 'San Francisco Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the San Francisco area. ... Wednesday 02/ ...'},\n",
       " {'url': 'https://weatherspark.com/h/y/557/2024/Historical-Weather-during-2024-in-San-Francisco-California-United-States',\n",
       "  'content': 'San Francisco Temperature History 2024\\nHourly Temperature in 2024 in San Francisco\\nCompare San Francisco to another city:\\nCloud Cover in 2024 in San Francisco\\nDaily Precipitation in 2024 in San Francisco\\nObserved Weather in 2024 in San Francisco\\nHours of Daylight and Twilight in 2024 in San Francisco\\nSunrise & Sunset with Twilight and Daylight Saving Time in 2024 in San Francisco\\nSolar Elevation and Azimuth in 2024 in San Francisco\\nMoon Rise, Set & Phases in 2024 in San Francisco\\nHumidity Comfort Levels in 2024 in San Francisco\\nWind Speed in 2024 in San Francisco\\nHourly Wind Speed in 2024 in San Francisco\\nHourly Wind Direction in 2024 in San Francisco\\nAtmospheric Pressure in 2024 in San Francisco\\nData Sources\\n See all nearby weather stations\\nLatest Report — 3:56 PM\\nWed, Jan 24, 2024\\xa0\\xa0\\xa0\\xa013 min ago\\xa0\\xa0\\xa0\\xa0UTC 23:56\\nCall Sign KSFO\\nTemp.\\n60.1°F\\nPrecipitation\\nNo Report\\nWind\\n6.9 mph\\nCloud Cover\\nMostly Cloudy\\n1,800 ft\\nRaw: KSFO 242356Z 18006G19KT 10SM FEW015 BKN018 BKN039 16/12 A3004 RMK AO2 SLP171 T01560122 10156 20122 55001\\n While having the tremendous advantages of temporal and spatial completeness, these reconstructions: (1) are based on computer models that may have model-based errors, (2) are coarsely sampled on a 50 km grid and are therefore unable to reconstruct the local variations of many microclimates, and (3) have particular difficulty with the weather in some coastal areas, especially small islands.\\n We further caution that our travel scores are only as good as the data that underpin them, that weather conditions at any given location and time are unpredictable and variable, and that the definition of the scores reflects a particular set of preferences that may not agree with those of any particular reader.\\n 2024 Weather History in San Francisco California, United States\\nThe data for this report comes from the San Francisco International Airport.'},\n",
       " {'url': 'https://www.extremeweatherwatch.com/cities/san-francisco/year-2024',\n",
       "  'content': \"Jump to Month: Year: What's the hottest temperature in San Francisco so far this year? As of February 11, the highest temperature recorded in San Francisco, California in 2024 is 73 °F which happened on January 29. Highest Temperatures: All-Time By Year Highest Temperatures in San Francisco in 2024\"},\n",
       " {'url': 'https://www.weathertab.com/en/g/e/02/united-states/california/san-francisco/',\n",
       "  'content': 'Free Long Range Weather Forecast for San Francisco, California February 2024. Detailed graphs of monthly weather forecast, temperatures, and degree days.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()\n",
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever\n",
    "자체 데이터를 검색하는 Retriever를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Introduction', 'language': 'en'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 검색을 수행할 인덱스를 채웠으므로 이를 tool(agent가 적절하게 사용하는 데 필요한 형식)로 쉽게 전환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다운스트림에서 사용할 도구 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mLangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "Skip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure\n",
      "\n",
      "more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special\n",
      "\n",
      "JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM (Large Language Model) applications. It can help with testing by providing capabilities for debugging, testing, evaluating, and monitoring chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs.\n",
      "\n",
      "Some ways LangSmith can help with testing include:\n",
      "1. Tracing: LangSmith offers tracing capabilities to help track and analyze the behavior of LLM applications during testing.\n",
      "2. Evaluation: LangSmith provides evaluation capabilities to assess the performance and accuracy of LLM models during testing.\n",
      "3. Monitoring: LangSmith allows for monitoring the performance of LLM applications in real-time to identify any issues or anomalies during testing.\n",
      "\n",
      "For more detailed information on how LangSmith can specifically assist with testing, you can refer to the LangSmith documentation and user guide.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM (Large Language Model) applications. It can help with testing by providing capabilities for debugging, testing, evaluating, and monitoring chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs.\\n\\nSome ways LangSmith can help with testing include:\\n1. Tracing: LangSmith offers tracing capabilities to help track and analyze the behavior of LLM applications during testing.\\n2. Evaluation: LangSmith provides evaluation capabilities to assess the performance and accuracy of LLM models during testing.\\n3. Monitoring: LangSmith allows for monitoring the performance of LLM applications in real-time to identify any issues or anomalies during testing.\\n\\nFor more detailed information on how LangSmith can specifically assist with testing, you can refer to the LangSmith documentation and user guide.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': \"I'm sorry, but I am not able to provide real-time weather information. However, you can easily check the weather in San Francisco by using a weather website or app like Weather.com or AccuWeather.\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in memory\n",
    "- Agent는 Stateless로 이전 상호작용을 기억하지 못합니다.\n",
    "- 메모리를 제공하려면 이전 채팅 이력을 전달해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is bob',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Bob! How can I assist you today, Bob?'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 메시지를 자동으로 추적하려면 이를 RunnableWithMessageHistory로 래핑할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "message_history = ChatMessageHistory()\n",
    "\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob!'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
