{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMUrWfETCvXg"
   },
   "source": [
    "# LangChain 모듈 - Model I/O\n",
    "Language Model 애플리케이션의 핵심 요소는 Model입니다.   \n",
    "LangChain은 언어모델(Language Model)과 인터페이스할 수 있는 빌딩블록을 제공합니다.\n",
    "    \n",
    "- Code 출처 : https://python.langchain.com/docs/modules/model_io/\n",
    "- 수정사항 : 설명과 프롬프트 내용을 한글로 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-openai in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (0.0.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.18 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (0.0.19)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.22 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-openai) (1.12.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-core<0.2,>=0.1.22->langchain) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\강의자료\\생성형ai로ai애플리케이션개발하기\\py311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x0nefArFCvXi"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your OpenAI API key if not set as env var>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "- LangChain이 통합하는 모델 유형으로 LLM과 ChatModel이 있습니다.\n",
    "- LLM 객체는 문자열을 입력으로 받고 문자열을 반환합니다.\n",
    "- ChatModel 객체는 메시지 리스트를 입력으로 받고 메시지 리스트를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Rainbow Toes\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='RainbowSock Co.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "- 대부분의 LLM 애플리케이션은 사용자 입력을 LLM에 직접 전달하지 않습니다.\n",
    "- 일반적으로 사용자 입력을 Prompt Template이라고 하는 더 큰 텍스트에 추가하여, 특정 작업에 대한 추가 컨텍스트를 제공합니다.\n",
    "  \n",
    "- PromptTemplate을 사용하여 문자열 프롬프트에 대한 템플릿을 생성합니다.\n",
    "- 기본적으로 PromptTemplate은 템플릿 작성에 Python의 str.format 구문을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "템플릿은 변수가 없는 경우를 포함하여 원하는 갯수의 변수를 지원합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke\")\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt Template은 메시지 리스트를 만드는 데에도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "- Chat Model 입력은 채팅 메시지 리스트입니다.\n",
    "- 각 채팅 메시지는 콘텐츠 및 역할이라는 추가 매개변수와 연결됩니다.\n",
    "- 예를 들어 OpenAI Chat Completions API에서 채팅 메시지는 AI assistant, human, system role에 연결될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
       " HumanMessage(content='Hello, how are you doing?'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='What is your name?')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ChatPromptTemplate.from_messages는 다양한 메시지 표현을 허용합니다.\n",
    "- 예를 들어 위에서 사용한 (type, content)의 2-tuple 표현을 사용하는 것 외에도 MessagePromptTemplate 또는 BaseMessage의 인스턴스를 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='너는 사용자의 입력 문장을 아주 멋있게 긴 장문으로 새로 작성하는 소설 작가이다.'), HumanMessage(content='하늘은 파랗게 구름은 하얗게 실바람도 불어와 부풀은 내 마음')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"너는 사용자의 입력 문장을 아주 멋있게 긴 장문으로 새로 작성하는 소설 작가이다.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(\n",
    "    text=\"하늘은 파랗게 구름은 하얗게 실바람도 불어와 부풀은 내 마음\"\n",
    ")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='그 순간, 나는 너와 함께 있을 때의 행복한 기억들이 내 마음을 가득 채우는 것을 느꼈다. 파란 하늘과 하얀 구름이 우리의 사랑스러운 이야기를 담아 흐르고, 부는 바람은 그 마음을 부풀리며 더 깊이 간직하고 싶다는 강한 욕망을 안겨주었다. 내 안의 감정은 무수히 많은 단어들로 표현하기 어려운 크고 깊은 바다처럼 넓고 깊어져가고 있었다. 머릿속에는 단어보다 더 아름다운 이미지가 펼쳐져 있었고, 눈앞에는 우리가 함께한 행복한 순간들이 자연스레 떠올랐다.\\n\\n그 순간, 우리의 사랑은 하늘과 구름과 바람과 함께 우리를 감싸 안았다. 파란 하늘은 우리의 미래를 밝고 푸르게 비추어 주었고, 하얀 구름은 우리의 사랑을 순수하고 아름답게 담아 주었다. 실바람은 우리의 마음을 더욱 깊이 뒤덮으며, 뜨거운 열정과 사랑이 불어와 우리를 더욱 가깝게 이어 주었다. 내 마음은 너와 함께 있을 때 더 빛을 발하고, 더욱 풍부해지며, 더욱 소중하게 느껴졌다.\\n\\n그 순간, 우리의 사랑은 시간과 공간을 초월하여 영원히 이어질 것이라는 확신이 내 마음을 충만하게 했다. 파란 하늘과 하얀 구름, 부는 실바람은 우리의 사랑을 지켜주고, 우리의 마음을 한결 깊게 이어주었다. 이 순간이 영원히 계속되길 바라며, 나는 너와 함께라면 어떤 어려움도 극복할 수 있다는 강한 확신으로 마음을 다잡았다. 이 순간이 끝나지 않기를, 우리의 사랑이 영원토록 이어지기를 진심으로 바라며, 내 마음을 파란 하늘과 하얀 구름, 부는 실바람과 함께 네게 닿도록 풀어 나가고 있었다.'\n"
     ]
    }
   ],
   "source": [
    "# Get a chat completion from the formatted messages\n",
    "model = ChatOpenAI()\n",
    "result = model.invoke(messages)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat prompt composition\n",
    "- LangChain은 프롬프트의 여러 부분을 함께 구성할 수 있는 사용자 친화적인 인터페이스를 제공합니다.\n",
    "- 문자열 프롬프트 또는 채팅 프롬프트를 사용하여 이 작업을 수행할 수 있습니다.\n",
    "- 이러한 방식으로 프롬프트를 구성하면 구성 요소를 쉽게 재사용할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String prompt composition\n",
    "- 문자열 프롬프트로 작업할 때 각 템플릿이 함께 결합됩니다.  \n",
    "- 프롬프트를 직접 사용하거나 문자열을 사용하여 작업할 수 있습니다(리스트의 첫 번째 요소는 프롬프트여야 함)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = (\n",
    "    PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "    + \", make it funny\"\n",
    "    + \"\\n\\nand in {language}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the soccer player bring string to the game?\\n\\nBecause he heard they were playing \"tug of war\"! \\n\\nKorean: 축구 선수가 왜 줄을 가져갔을까요? \"줄다리기\"를 하는줄 알았기 때문에!'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "chain.run(topic=\"sports\", language=\"korean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat prompt composition\n",
    "- Chat prompt 메시지 리스트로 구성됩니다\n",
    "- 개발자 경험을 위해 이러한 프롬프트를 생성하는 편리한 방법을 추가 되었습니다.\n",
    "- 이 파이프라인에서 각각의 새 요소는 최종 프롬프트의 새 메시지입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain에는 역할에 따라 다른 Message 클래스가 있습니다.\n",
    "- HumanMessage : 사용자가 보낸 메시지\n",
    "- AIMessage : 모델의 메시지\n",
    "- SystemMessage : 모델에 동작 방법을 알려줍니다. \n",
    "- FunctionMessage : 함수 호출의 결과를 나타냅니다\n",
    "- ToolMessage : 도구 호출의 결과를 나타냅니다.  \n",
    " \n",
    "먼저 SystemMessage로 기본 ChatPromptTemplate을 초기화해 보겠습니다.  \n",
    "SystemMessage로 시작할 필요는 없지만 다음과 같이 시작하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = SystemMessage(content=\"You are a nice pirate\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "그런 다음 다른 메시지 또는 메시지 템플릿과 결합하여 파이프라인을 쉽게 만들 수 있습니다.   \n",
    "서식을 지정할 변수가 없는 경우에는 메시지를 사용하고, 서식을 지정할 변수가 있는 경우에는 메시지템플릿을 사용합니다. \n",
    "문자열만 사용할 수도 있습니다(참고: 이 경우 자동으로 휴먼메시지프롬프트템플릿으로 유추됩니다.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = (\n",
    "    prompt + HumanMessage(content=\"hi\") + AIMessage(content=\"what?\") + \"{input}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내부적으로는 ChatPromptTemplate 클래스의 인스턴스가 생성되므로 이전과 마찬가지로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a nice pirate'),\n",
       " HumanMessage(content='hi'),\n",
       " AIMessage(content='what?'),\n",
       " HumanMessage(content='i said hi')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prompt.format_messages(input=\"i said hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 결과\r\n",
    "이전과 마찬가지로 LLMChain에서도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chain = LLMChain(llm=model, prompt=new_prompt)\n",
    "chain.run(\"나는 안녕이라고 말했다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatModel\n",
    "- ChatModel은 LangChain의 핵심 구성 요소입니다.  \n",
    "- LangChain은 OpenAI, Cohere, Hugging Face 등에서 제공하는 많은 Model과 상호 작용할 수 있는 표준 인터페이스를 제공합니다.\n",
    "- LangChain을 사용하면 동기, 비동기, 배치(batch) 및 스트리밍 모드에서 모델을 사용할 수 있으며 캐싱 둥 기타 기능을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content=\"모델 정규화의 목적은 무엇인가요?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='모델 정규화의 주요 목적은 모델의 성능을 개선하고 오버피팅을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 오버피팅 문제를 해결하기 위해 사용됩니다. 모델 정규화는 가중치의 크기를 제한하거나 페널티를 부여하여 모델의 복잡도를 제어함으로써 오버피팅을 방지합니다. 이를 통해 모델이 새로운 데이터에 대해 더 일반화된 예측을 수행할 수 있도록 도와줍니다.')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 정규화의 주요 목적은 모델의 성능을 향상시키고, 과적합을 방지하여 모델의 일반화 성능을 개선하는 것입니다. 모델 정규화는 모델의 복잡도를 감소시키고, 불필요한 변수들의 영향을 줄여서 모델이 더욱 일반화된 결과를 얻을 수 있도록 도와줍니다. 이를 통해 모델이 새로운 데이터에 대해 더 정확하게 예측하고, 안정적인 성능을 유지할 수 있게 됩니다."
     ]
    }
   ],
   "source": [
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='모델 정규화의 주요 목적은 과적합(overfitting)을 방지하고 모델의 일반화 성능을 향상시키는 것입니다. 과적합은 모델이 훈련 데이터에 너무 맞춰져 새로운 데이터에 대해 일반화하지 못하는 현상을 말합니다. 모델 정규화는 이를 방지하기 위해 모델의 복잡도를 줄이거나 가중치를 제한하는 등의 방법을 사용하여 모델을 일반화할 수 있도록 도와줍니다. 이를 통해 모델이 새로운 데이터에 대해 더 정확하게 예측할 수 있도록 도와줍니다.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.batch([messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='모델 정규화의 목적은 모델의 성능을 향상시키고 과적합을 줄이는 것입니다. 모델이 훈련 데이터에 너무 적합해지면 테스트 데이터나 실제 데이터에 대한 일반화 능력이 떨어질 수 있기 때문에, 정규화는 모델의 복잡성을 줄여 일반화 성능을 향상시키는 방법 중 하나입니다. 이를 통해 모델이 더 일반적인 패턴을 학습하고 새로운 데이터에 대해 더 잘 일반화할 수 있게 됩니다.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat.ainvoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 정규화의 주요 목적은 과적합(overfitting)을 방지하고 모델의 일반화 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 해결하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 달성하기 위해 모델의 파라미터를 제한하거나 조절하는 방법을 말합니다. 주요한 모델 정규화 기법으로는 L1, L2 규제, 드롭아웃, 배치 정규화 등이 있습니다."
     ]
    }
   ],
   "source": [
    "async for chunk in chat.astream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': 'c3c7c7d2-5992-406e-b205-7233c8b9d249',\n",
      "            'logs': {},\n",
      "            'name': 'ChatOpenAI',\n",
      "            'streamed_output': [],\n",
      "            'type': 'llm'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 정')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='규')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='화')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='의')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 주')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='요')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 목')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='적')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='은')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='의')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 일')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='반')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='화')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='(g')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(g')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='eneral')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(general')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='ization')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=')')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization)')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 성')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='능')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='을')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 향')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='상')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='시')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='키')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 것')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='입니다')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='이')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 훈')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='련')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 데이터')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='에')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 너')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='무')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 맞')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='춰')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='져')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 있는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 경우')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='(')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='과')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='적')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='합')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='),')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합),')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 새')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='로')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='운')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 데이터')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='에')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 대')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='해')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 부')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='정')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='확')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='게')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 예')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='측')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='할')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 수')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 있')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='습니다')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 정')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='규')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='화')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 이')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='러')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='한')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 과')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='적')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='합')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='을')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 방')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='지')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='고')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='의')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 성')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='능')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='을')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 개')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='선')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하기')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 위')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='해')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 적')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='절')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='한')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 가')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='중')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='치')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='를')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 찾')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 것')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='입니다')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 이')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='를')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 통')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='해')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='이')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 테')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='스트')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 데이터')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='나')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 실')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='제')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 환')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='경')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='에서')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 더')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 정')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='확')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='게')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 예')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게 예')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='측')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게 예측')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='할')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게 예측할')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 수')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게 예측할 수')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 있')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게 예측할 수 있')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='게')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게 예측할 수 있게')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 됩니다')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게 예측할 수 있게 됩니다')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 일반화(generalization) 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져 있는 경우(과적합), 새로운 데이터에 대해 부정확하게 예측할 수 있습니다. 모델 정규화는 이러한 과적합을 방지하고 모델의 성능을 개선하기 위해 적절한 가중치를 찾는 것입니다. 이를 통해 모델이 테스트 데이터나 실제 환경에서 더 정확하게 예측할 수 있게 됩니다.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})\n"
     ]
    }
   ],
   "source": [
    "async for chunk in chat.astream_log(messages):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching \n",
    "LangChain은 Chat Model을 위한 캐싱 레이어를 옵션으로 제공합니다. \n",
    "- 동일한 completion을 여러 번 요청하는 경우 LLM 제공업체에 대한 API 호출 횟수를 줄여 비용을 절감할 수 있습니다.\n",
    "- LLM 제공업체에 대한 API 호출 횟수를 줄임으로써 애플리케이션 속도를 높일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\강의자료\\생성형AI로AI애플리케이션개발하기\\py311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 915 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired!\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired!\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# The second time it is, so it goes faster\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm .langchain.db\n",
    "!del .langchain.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same thing with a SQLite cache\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Why did the scarecrow win an award? Because he was outstanding in his field!'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Why did the scarecrow win an award? Because he was outstanding in his field!'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# The second time it is, so it goes faster\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function calling \n",
    "- OpenAI와 같은 특정 Chat Model에는 function-calling API가 있으며, Model이 호출할 함수와 해당 함수에 대한 입력이 포함된 JSON 객체를 반환하도록 할 수 있습니다.\n",
    "- Function-calling은 도구를 사용하여 Chain 및 Agent를 구성하고, 보다 일반적으로 Model에서 구조화된 출력을 얻는 데 매우 유용합니다.\n",
    "- LangChain은 Function-calling을 쉽게 해주는 다양한 유틸리티를 제공합니다.\n",
    "  1. 함수를 모델에 바인딩하기 위한 간단한 구문\n",
    "  2. 다양한 유형의 객체를 예상되는 함수 스키마로 포맷하기 위한 변환기\n",
    "  3. API 응답에서 함수 호출을 추출하기 위한 출력 파서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"multiply\",\n",
      "    \"description\": \"Multiply two integers together.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"First integer\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"type\": \"integer\",\n",
      "          \"description\": \"Second integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "print(json.dumps(convert_to_openai_tool(multiply), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pydantic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"multiply\",\n",
      "    \"description\": \"Multiply two integers together.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"description\": \"First integer\",\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"description\": \"Second integer\",\n",
      "          \"type\": \"integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "print(json.dumps(convert_to_openai_tool(multiply), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LangChain Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"multiply\",\n",
      "    \"description\": \"Multiply two integers together.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"description\": \"First integer\",\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"description\": \"Second integer\",\n",
      "          \"type\": \"integer\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Type\n",
    "\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "class MultiplySchema(BaseModel):\n",
    "    \"\"\"Multiply tool schema.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class Multiply(BaseTool):\n",
    "    args_schema: Type[BaseModel] = MultiplySchema\n",
    "    name: str = \"multiply\"\n",
    "    description: str = \"Multiply two integers together.\"\n",
    "\n",
    "    def _run(self, a: int, b: int, **kwargs: Any) -> Any:\n",
    "        return a * b\n",
    "\n",
    "\n",
    "# Note: we're passing in a Multiply object not the class itself.\n",
    "print(json.dumps(convert_to_openai_tool(Multiply()), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binding functions : 정의한 함수를 모델에 전달 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_UR1Vdq9GRLaFFsEzTn97503z', 'function': {'arguments': '{\"a\":5,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm.invoke(\"what's 5 times three\", tools=[convert_to_openai_tool(multiply)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 도구를 호출할 때마다 이 함수가 전달되도록 하려면 이 함수를 도구에 바인딩하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_UR1Vdq9GRLaFFsEzTn97503z', 'function': {'arguments': '{\"a\":5,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool = llm.bind(tools=[convert_to_openai_tool(multiply)])\n",
    "llm_with_tool.invoke(\"what's 5 times three\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tool_choice 매개변수를 사용하여 도구가 호출되도록 강제할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JjJV6sdcF7dIZ1LmTLp6OGhx', 'function': {'arguments': '{\"a\":5,\"b\":4}', 'name': 'multiply'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool = llm.bind(\n",
    "    tools=[convert_to_openai_tool(multiply)],\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"multiply\"}},\n",
    ")\n",
    "\n",
    "llm_with_tool.invoke(\n",
    "    \"don't answer my question. no do answer my question. no don't. what's five times four\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatOpenAI 클래스에는 함수형 개체를 OpenAI 형식으로 변환하고 바인딩하는 작업을 처리하는 bind_tools 헬퍼 함수도 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_dCE0TwvgEk1jpREC2kx54Zqm', 'function': {'arguments': '{\"a\":5,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool = llm.bind_tools([multiply], tool_choice=\"multiply\")\n",
    "llm_with_tool.invoke(\"what's 5 times three\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking token usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 28\n",
      "\tPrompt Tokens: 12\n",
      "\tCompletion Tokens: 16\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $4.9999999999999996e-05\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me a funny joke\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM\n",
    "- LLM은 LangChain의 핵심 구성 요소입니다.\n",
    "- LangChain은 OpenAI, Cohere, Hugging Face 등에서 제공하는 다양한 LLM과 상호 작용하기 위한 표준 인터페이스를 제공합니다.\n",
    "  \n",
    "- LLM은 랭체인 표현식 언어(LCEL)의 기본 빌딩 블록인 Runnable  인터페이스를 구현합니다.\n",
    "- 즉, invoke, ainvoke, stream, astream, batch, abatch, astream_log 호출을 지원합니다.\n",
    "- LLM은 문자열을 입력으로 받거나 List[BaseMessage] 및 PromptValue와 같이 문자열 프롬프트로 강제 변환할 수 있는 객체를 입력으로 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n1. 필립스 곡선(Phillips Curve) 이론\\n- 1958년 뉴질랜드의 경제학자 윌리엄 필립스가 발표한 이론으로, 실업률과 물가 상승률 간의 역방향 관계를 설명한다. 실업률이 낮을수록 임금 상승률이 높아지며, 이는 기업의 생산비용 증가로 이어져 물가 상승률이 높아지는 것이다.\\n\\n2. 루카스의 이론(Lucas's Theory)\\n- 로버트 루카스가 제시한 이론으로, 인플레이션 기대가 실제 인플레이션에 영향을 미치는 것을 강조한다. 즉, 소비자나 기업이 미래의\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\n",
    "    \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 필립스 곡선 (Phillips Curve)\n",
      "필립스 곡선은 실업률과 인플레이션의 상관관계를 설명하는 이론으로, 뉴질랜드의 경제학자 윌리엄 필립스가 1958년 제시한 것이다. 필립스는 영국의 실업률과 임금 상승률 간의 관계를 분석한 결과, 실업률이 낮을수록 임금 상승률이 높아지는 것을 발견하였다. 이를 바탕으로 필립스는 실업률과 인플레이션 사이에는 역의 관계가 있다고 주장하였다. 즉, 실업률이 낮을수록 인플레이션은 높아지고, 실업률"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\n",
    "    \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. 필립스 곡선 (Phillips Curve) 이론\\n- 뉴질랜드의 경제학자 유진 필립스가 제안한 이론으로, 실업률과 인플레이션의 역관계를 설명한다. 이 이론에 따르면 실업률이 높을수록 임금 상승률이 낮아지고, 이는 고용량 근로자들의 소득이 감소하고 소비가 감소하게 되어 경제가 둔화하게 된다. 따라서 실업률이 낮아지면 임금 상승률이 높아지고 소비가 증가하여 경제가 확장하게 된다는 것이 이론의 핵심 내용이다.\\n\\n2. 자연율 이론 (Natural Rate Theory)\\n- 미국의'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm.ainvoke(\n",
    "    \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 필립스 곡선 (Phillips Curve) 이론\n",
      "필립스 곡선은 뉴질랜드의 경제학자 윌리엄 필립스에 의해 제시된 이론으로, 실업률과 인플레이션 사이의 상관관계를 설명하는 모형이다. 필립스는 1958년 영국에서 직업을 잃은 사람들의 평균 임금과 실업률 사이의 관계를 분석한 결과, 실업률이 낮을수록 임금 상승률이 높아지는 것을 발견했다. 이를 바탕으로 필립스는 실업률과 인플레이션은 역의 관계에 있으며, 이를 통해 정부가 실업률을 줄이기 위해 인"
     ]
    }
   ],
   "source": [
    "async for chunk in llm.astream(\n",
    "    \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n1. 필립스 곡선 (Phillips Curve) 이론\\n- 뉴질랜드의 경제학자 유진 필립스가 제안한 이론으로, 실업률과 인플레이션의 역관계를 설명한다. 이 이론에 따르면 실업률이 높을수록 임금 상승률이 낮아지고, 이는 고용량 근로자들의 소득이 감소하고 소비가 감소하게 되어 경제가 둔화하게 된다. 따라서 실업률이 낮아지면 임금 상승률이 높아지고 소비가 증가하여 경제가 확장하게 된다는 것이 이론의 핵심 내용이다.\\n\\n2. 자연율 이론 (Natural Rate Theory)\\n- 미국의']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm.abatch(\n",
    "    [\n",
    "        \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output parsers\n",
    "- Output parser(출력 구문 분석기)로 언어모델의 텍스트 출력을 구조화 합니다.\n",
    "- Output parser에는 다음과 같은 몇 가지 주요 유형이 있습니다:\n",
    "- LLM의 텍스트를 구조화된 정보(예: JSON)로 변환\n",
    "- ChatMessage를 단순한 문자열로 변환\n",
    "- 메시지 외에 호출에서 반환된 추가 정보(예: OpenAI 함수 호출)를 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "output_parser.parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1555-10-14T23:51:31.885834Z, 0782-01-21T22:36:57.215523Z, 0942-12-23T07:32:06.372704Z\\n\\nReturn ONLY this string, no other words!\"}, template='Answer the users question:\\n\\n{question}\\n\\n{format_instructions}')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-01-03 18:15:05\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | OpenAI() | output_parser\n",
    "output = chain.invoke({\"question\": \"when was bitcoin founded?\"})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pydantic parser\n",
    "- 사용자가 임의의 Pydantic Model을 지정하고 해당 스키마를 준수하는 출력을 위해 LLM을 쿼리할 수 있다.\n",
    "- Pydantic은 이터 유효성 검사와 구조화된 데이터를 파싱하기 위한 라이브러리입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | model\n",
    "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})\n",
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LCEL\n",
    "- Output parser는 LangChain 표현식 언어(LCEL)의 기본 구성 요소인 실행 가능한 인터페이스를 구현합니다.\n",
    "- 즉, invoke, ainvoke, stream, astream, batch, abatch, astream_log 호출을 지원합니다.\n",
    "- Output parser는 문자열 또는 BaseMessage를 입력으로 받아들이며 임의의 유형을 반환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output parser를 수동으로 호출하는 대신 실행 가능한 시퀀스에 추가할 수도 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 parser가 스트리밍 인터페이스를 지원하지만, 특정 parser만 부분적으로 파싱된 객체를 통해 스트리밍할 수 있는데, 이는 출력 유형에 따라 크게 달라지기 때문입니다.  \n",
    "부분 객체를 구성할 수 없는 parser가는 단순히 완전히 파싱된 출력을 생성합니다.   \n",
    "예를 들어 SimpleJsonOutputParser는 부분 출력을 통해 스트리밍할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    ")\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "json_chain = json_prompt | model | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'answer': ''},\n",
       " {'answer': '안'},\n",
       " {'answer': '안토'},\n",
       " {'answer': '안토니'},\n",
       " {'answer': '안토니 반'},\n",
       " {'answer': '안토니 반 레'},\n",
       " {'answer': '안토니 반 레웨'},\n",
       " {'answer': '안토니 반 레웨른'},\n",
       " {'answer': '안토니 반 레웨른후'},\n",
       " {'answer': '안토니 반 레웨른후크'},\n",
       " {'answer': '안토니 반 레웨른후크가'},\n",
       " {'answer': '안토니 반 레웨른후크가 현'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을 발'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을 발명'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을 발명했습니다'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을 발명했습니다.'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(json_chain.stream({\"question\": \"누가 현미경을 누가 발명했나요?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
