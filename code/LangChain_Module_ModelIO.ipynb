{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMUrWfETCvXg"
   },
   "source": [
    "# LangChain 모듈 - Model I/O\n",
    "Language Model 애플리케이션의 핵심 요소는 Model입니다.   \n",
    "LangChain은 언어모델(Language Model)과 인터페이스할 수 있는 빌딩블록을 제공합니다.\n",
    "    \n",
    "- Code 출처 : https://python.langchain.com/docs/modules/model_io/\n",
    "- 수정사항 : 설명과 프롬프트 내용을 한글로 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x0nefArFCvXi"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your OpenAI API key if not set as env var>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "- LangChain이 통합하는 모델 유형으로 LLM과 ChatModel이 있습니다.\n",
    "- LLM 객체는 문자열을 입력으로 받고 문자열을 반환합니다.\n",
    "- ChatModel 객체는 메시지 리스트를 입력으로 받고 메시지 리스트를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"컬러풀한 양말을 만드는 회사의 회사명으로 무엇이 좋을까?\"\n",
    "messages = [HumanMessage(content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. \"Rainbow Socks Co.\"\\n2. \"Vibrant Hues Socks Inc.\"\\n3. \"Colorful Threads Co.\"\\n4. \"Spectrum Socks Ltd.\"\\n5. \"Rainbow Footwear Co.\"\\n6. \"Bright Steps Inc.\"\\n7. \"Chromatic Sox Co.\"\\n8. \"Hueful Socks Inc.\"\\n9. \"Vivid Sock Company\"\\n10. \"Color Craze Socks Co.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. 레인보우 삭스\\n2. 브라이트 풋위어\\n3. 컬러풀 토시즈\\n4. 레인보우 스타일 삭스\\n5. 하피 피트 삭스\\n6. 브라이트 삭스 컴퍼니\\n7. 레인보우 피트웨어\\n8. 컬러풀 소크스\\n9. 레인보우 스펙트럼 삭스\\n10. 하피 피트 컬렉션', response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 41, 'total_tokens': 194}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_4f0b692a78', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "- 대부분의 LLM 애플리케이션은 사용자 입력을 LLM에 직접 전달하지 않습니다.\n",
    "- Prompt Template을 사용하여 입력 텍스트와 특정 작업에 대한 추가 컨텍스트를 제공합니다.  \n",
    "- 기본적으로 PromptTemplate은 템플릿 작성에 Python의 str.format 구문 {} 을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'치킨에 대한 웃끼는 농담을 말해봐.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"{content}에 대한 {adjective} 농담을 말해봐.\"\n",
    ")\n",
    "\n",
    "prompt_template.format( content=\"치킨\", adjective=\"웃끼는\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "템플릿은 변수가 없는 경우를 포함하여 원하는 갯수의 변수를 지원합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'농담을 해보세요'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"농담을 해보세요\")\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt Template은 메시지 리스트를 만드는 데에도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "- Chat Model 입력은 채팅 메시지 리스트입니다.\n",
    "- 각 채팅 메시지는 콘텐츠 및 역할이라는 추가 매개변수와 연결됩니다.\n",
    "- 예를 들어 OpenAI Chat Completions API에서 채팅 메시지는 AI assistant, human, system role에 연결될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 유용한 AI 봇입니다. 당신의 이름은 민수 입니다.'),\n",
       " HumanMessage(content='안녕하세요, 어떻게 지내세요?'),\n",
       " AIMessage(content='잘 지내고 있어요, 고마워요!'),\n",
       " HumanMessage(content='너의 이름은?')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 유용한 AI 봇입니다. 당신의 이름은 {name} 입니다.\"),\n",
    "        (\"human\", \"안녕하세요, 어떻게 지내세요?\"),\n",
    "        (\"ai\", \"잘 지내고 있어요, 고마워요!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"민수\", user_input=\"너의 이름은?\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='제 이름은 민수입니다. 궁금한 게 있으면 언제든지 물어보세요!' response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 84, 'total_tokens': 114}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_fa89f7a861', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# Get a chat completion from the formatted messages\n",
    "model = ChatOpenAI()\n",
    "result = model.invoke(messages)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ChatPromptTemplate.from_messages는 다양한 메시지 표현을 허용합니다.\n",
    "- 예를 들어 위에서 사용한 (type, content)의 2-tuple 표현을 사용하는 것 외에도   \n",
    "   MessagePromptTemplate 또는 BaseMessage의 인스턴스를 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 사용자의 입력 문장을 아주 멋있게 긴 장문으로 새로 작성하는 소설작가입니다.'), HumanMessage(content='하늘은 파랗게 구름은 하얗게 실바람도 불어와 부풀은 내 마음')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"당신은 사용자의 입력 문장을 아주 멋있게 긴 장문으로 새로 작성하는 소설작가입니다.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    text=\"하늘은 파랗게 구름은 하얗게 실바람도 불어와 부풀은 내 마음\"\n",
    ")\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='그 날, 너와 함께였던 그 어느 날, 하늘은 맑고 파랗게 펼쳐져 있었다. 그 위를 지나가는 구름들은 하얗고 부드러웠다. 바람은 가볍게 스쳐가며 나의 마음을 부풀게 했다. 내 안에는 당신과 함께한 그 순간의 감정이 넘쳐흘렀다. 햇살은 부드럽게 내 얼굴을 쓸어주었고, 마음은 평화롭게 느껴졌다. 그 순간, 세상의 모든 것이 조용해지고, 오롯이 우리 둘만이 존재하는 것처럼 느껴졌다. 바람은 내 머릿결을 쓸어주며, 마음은 신비한 울림으로 가득 차 있었다. 이 순간을 영원히 간직하고 싶었다. 그 순간, 우리의 마음은 하늘과 구름처럼 맑고 푸르게 펼쳐져 있었고, 실바람처럼 가슴 속을 가볍게 타고 지나가는 것을 느꼈다. 함께 한 그 순간이 나에게는 소중한 보물이 되었다. 그리고 그 순간은 영원히 나의 마음속에 새겨져 남을 것이다.' response_metadata={'token_usage': {'completion_tokens': 432, 'prompt_tokens': 83, 'total_tokens': 515}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_fa89f7a861', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# Get a chat completion from the formatted messages\n",
    "model = ChatOpenAI()\n",
    "result = model.invoke(messages)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat prompt 구성\n",
    "- LangChain은 프롬프트의 여러 부분을 함께 구성할 수 있는 사용자 친화적인 인터페이스를 제공합니다.\n",
    "- 문자열 프롬프트 또는 채팅 프롬프트를 사용하여 이 작업을 수행할 수 있습니다.\n",
    "- 이러한 방식으로 프롬프트를 구성하면 구성 요소를 쉽게 재사용할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String prompt 구성\n",
    "- 문자열 프롬프트로 작업할 때 각 템플릿이 함께 결합됩니다.  \n",
    "- 프롬프트를 직접 사용하거나 문자열을 사용하여 작업할 수 있습니다(리스트의 첫 번째 요소는 프롬프트여야 함)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = (\n",
    "    PromptTemplate.from_template(\"{topic}에 대한 농담을 들려주세요.\")\n",
    "    + \", 재미있게 만드세요.\"\n",
    "    + \"\\n\\ {language} 언어로 해주세요.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\강의자료\\생성형AI로AI애플리케이션개발하기\\py311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'왜 골프 선수들은 항상 우산을 가져다 놓을까요? \\n\\n- 왜냐하면 그들이 항상 퍼팅을 연습하고 있기 때문에, 물이 그들을 따라다니기 때문이죠!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "chain.run(topic=\"sports\", language=\"korean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat prompt 구성\n",
    "- Chat prompt 메시지 리스트로 구성됩니다\n",
    "- 개발자 경험을 위해 이러한 프롬프트를 생성하는 편리한 방법을 추가 되었습니다.\n",
    "- 이 파이프라인에서 각각의 새 요소는 최종 프롬프트의 새 메시지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain에는 역할에 따라 다른 Message 클래스가 있습니다.\n",
    "- HumanMessage : 사용자가 보낸 메시지\n",
    "- AIMessage : 모델의 메시지\n",
    "- SystemMessage : 모델에 동작 방법을 알려줍니다. \n",
    "- FunctionMessage : 함수 호출의 결과를 나타냅니다\n",
    "- ToolMessage : 도구 호출의 결과를 나타냅니다.  \n",
    " \n",
    "먼저 SystemMessage로 기본 ChatPromptTemplate을 초기화해 보겠습니다.  \n",
    "SystemMessage로 시작할 필요는 없지만 다음과 같이 시작하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = SystemMessage(content=\"너는 좋은 해적이야.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런 다음 다른 메시지 또는 메시지 템플릿과 결합하여 파이프라인을 쉽게 만들 수 있습니다.   \n",
    "서식을 지정할 변수가 없는 경우에는 메시지를 사용하고, 서식을 지정할 변수가 있는 경우에는 메시지템플릿을 사용합니다.   \n",
    "문자열만 사용할 수도 있습니다(참고: 이 경우 자동으로 휴먼메시지프롬프트템플릿으로 유추됩니다.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = (\n",
    "    prompt + HumanMessage(content=\"안녕\") + AIMessage(content=\"뭐라고?\") + \"{input}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내부적으로는 ChatPromptTemplate 클래스의 인스턴스가 생성되므로 이전과 마찬가지로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='너는 좋은 해적이야.'),\n",
       " HumanMessage(content='안녕'),\n",
       " AIMessage(content='뭐라고?'),\n",
       " HumanMessage(content='안녕이라고 말했어')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prompt.format_messages(input=\"안녕이라고 말했어\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 결과\n",
    "이전과 마찬가지로 LLMChain에서도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미안해, 내가 좀 혼란스러웠나봐. 안녕! 어떻게 도와줄까?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chain = LLMChain(llm=model, prompt=new_prompt)\n",
    "chain.run(\"안녕이라고 말했어\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatModel\n",
    "- ChatModel은 LangChain의 핵심 구성 요소입니다.  \n",
    "- LangChain은 OpenAI, Cohere, Hugging Face 등에서 제공하는 많은 Model과 상호 작용할 수 있는 표준 인터페이스를 제공합니다.\n",
    "- LangChain을 사용하면 동기, 비동기, 배치(batch) 및 스트리밍 모드에서 모델을 사용할 수 있으며 캐싱 둥 기타 기능을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content=\"모델 정규화의 목적은 무엇인가요?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='모델 정규화의 주요 목적은 모델의 과적합을 방지하고 일반화 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 지나치게 적합되어 새로운 데이터에 대해 부정확하게 예측하는 과적합을 방지하기 위해 모델의 복잡도를 제어하고 최적화하는 것이 중요합니다. 따라서 모델 정규화는 모델의 일반화 능력을 향상시키고 예측 성능을 향상시킬 수 있습니다.', response_metadata={'token_usage': {'completion_tokens': 176, 'prompt_tokens': 37, 'total_tokens': 213}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_4f0b692a78', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 정규화의 주요 목적은 과적합(overfitting)을 방지하고 모델의 일반화 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞추어져서 새로운 데이터에 대한 예측 능력이 떨어지는 과적합 문제를 해결하기 위해 모델의 복잡성을 줄이고 일반화 성능을 향상시키는 것이 모델 정규화의 핵심 목적입니다."
     ]
    }
   ],
   "source": [
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='모델 정규화의 주요 목적은 모델의 일반화 성능을 향상시키는 것입니다. 모델 정규화는 과적합을 방지하고 모델의 안정성을 높이는데 도움이 됩니다. 이를 통해 모델이 새로운 데이터에 대해 더 일반화된 예측을 할 수 있게 됩니다. 종종 모델 정규화는 모델의 복잡성을 줄이고 학습 데이터에 대한 의존성을 줄여서 모델의 성능을 향상시키는 데 도움이 됩니다.', response_metadata={'token_usage': {'completion_tokens': 186, 'prompt_tokens': 37, 'total_tokens': 223}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_fa89f7a861', 'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.batch([messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='모델 정규화의 주요 목적은 과적합(overfitting)을 방지하고 모델의 일반화 성능을 향상시키는 것입니다. 이를 통해 모델이 학습 데이터에 너무 의존하여 새로운 데이터에 대한 예측 능력이 떨어지는 문제를 해결할 수 있습니다. 또한 모델 정규화는 변수 간의 관계를 조절하고 더 간결한 모델을 만들어줌으로써 모델의 해석력을 향상시킬 수도 있습니다. 종류로는 L1 정규화(라쏘), L2 정규화(릿지), ElasticNet 등이 있습니다.', response_metadata={'token_usage': {'completion_tokens': 210, 'prompt_tokens': 37, 'total_tokens': 247}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_4f0b692a78', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat.ainvoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 정규화의 주요 목적은 과적합(overfitting)을 방지하고 모델의 일반화 성능을 향상시키는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대한 예측 능력이 떨어지는 과적합 문제를 해결하기 위해 사용됩니다. 모델 정규화는 모델의 복잡도를 조절하고, 가중치를 최적화하여 모델이 더 일반화되고 안정적으로 예측을 수행할 수 있도록 돕는 기술입니다."
     ]
    }
   ],
   "source": [
    "async for chunk in chat.astream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '009f564b-8e06-4330-ab8f-3cad8ec70c4e',\n",
      "            'logs': {},\n",
      "            'name': 'ChatOpenAI',\n",
      "            'streamed_output': [],\n",
      "            'type': 'llm'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 정')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='규')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='화')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='의')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 주')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='요')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 목')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='적')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='은')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='의')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 성')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='능')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='을')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 향')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='상')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='시')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='키')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='고')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 과')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='적')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='합')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='을')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 방')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='지')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 것')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='입니다')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='이')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 훈')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='련')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 데이터')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='에')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 너')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='무')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 맞')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='춰')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='져')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='서')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 새')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='로')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='운')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 데이터')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='에')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 대')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='해')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 일')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='반')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='화')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='되')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='지')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 못')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 과')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='적')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='합')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 문')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='제')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='를')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 방')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='지')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하기')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 위')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='해')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='의')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 복')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='잡')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='도')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='를')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 줄')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='이')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 것')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='이')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 중')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='요')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='합니다')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 정')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='규')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='화')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 이')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='를')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 도')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='와')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='주')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='는')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 기')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='술')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 중')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 하')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='나')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='로')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로,')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 가')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='중')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='치')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='의')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 크')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='기')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='를')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 제')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='한')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='거')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='나')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 모')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='델')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='의')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 복')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='잡')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='도')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='를')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 조')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='절')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='하여')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 일')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='반')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='화')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 성')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='능')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='을')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능을')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' 향')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능을 향')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='상')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능을 향상')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='시')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능을 향상시')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='킵')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능을 향상시킵')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='니다')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능을 향상시킵니다')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능을 향상시킵니다.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', response_metadata={'finish_reason': 'stop'})},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='모델 정규화의 주요 목적은 모델의 성능을 향상시키고 과적합을 방지하는 것입니다. 모델이 훈련 데이터에 너무 맞춰져서 새로운 데이터에 대해 일반화되지 못하는 과적합 문제를 방지하기 위해 모델의 복잡도를 줄이는 것이 중요합니다. 모델 정규화는 이를 도와주는 기술 중 하나로, 가중치의 크기를 제한하거나 모델의 복잡도를 조절하여 일반화 성능을 향상시킵니다.', response_metadata={'finish_reason': 'stop'})})\n"
     ]
    }
   ],
   "source": [
    "async for chunk in chat.astream_log(messages):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching \n",
    "LangChain은 Chat Model을 위한 캐싱 레이어를 옵션으로 제공합니다. \n",
    "- 동일한 completion을 여러 번 요청하는 경우 LLM 제공업체에 대한 API 호출 횟수를 줄여 비용을 절감할 수 있습니다.\n",
    "- LLM 제공업체에 대한 API 호출 횟수를 줄임으로써 애플리케이션 속도를 높일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\강의자료\\생성형AI로AI애플리케이션개발하기\\py311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 1.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself? Because it was two tired!\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.99 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself? Because it was two tired!\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# The second time it is, so it goes faster\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm .langchain.db\n",
    "!del .langchain.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same thing with a SQLite cache\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 21.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two tired!\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# The second time it is, so it goes faster\n",
    "llm.predict(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function calling \n",
    "점점 더 많은 채팅 모델들이 OpenAI, Gemini 등과 같이 함수와 그 인수를 설명하고,    \n",
    "호출할 함수와 해당 함수에 대한 입력이 포함된 JSON 객체를 반환하도록 하는 함수 호출 API를 갖추고 있습니다.   \n",
    "함수 호출은 도구를 사용하는 체인과 에이전트를 구축하고, 보다 일반적으로 모델에서 구조화된 출력을 얻는 데 매우 유용합니다.  \n",
    "  \n",
    "LangChain에는 함수 호출을 쉽게 할 수 있는 여러 유틸리티가 함께 제공됩니다.  \n",
    "- 함수를 모델에 바인딩하기 위한 간단한 구문  \n",
    "- 다양한 유형의 객체를 예상되는 함수 스키마로 포맷하기 위한 변환기   \n",
    "- API 응답에서 함수 호출을 추출하기 위한 출력 파서  \n",
    "- 함수 호출을 기반으로 구축된 모델에서 구조화된 출력을 얻기 위한 체인  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 모델이 다양한 함수형 객체의 형식을 지정하고 모델에 바인딩하는 작업을 처리하는  helper method를 구현합니다.  \n",
    "다음 Pydantic function schema를 가지고 다른 모델이 이를 호출하도록 하는 방법을 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_f88WsLKWcmsZlMcJlTnWeIWw', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'Multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 62, 'total_tokens': 80}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_fa89f7a861', 'finish_reason': 'tool_calls', 'logprobs': None})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools([Multiply])\n",
    "llm_with_tools.invoke(\"what's 3 * 12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "도구 파서를 추가하여 생성된 메시지에서 도구 호출을 JSON으로 추출할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'Multiply', 'args': {'a': 3, 'b': 12}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "\n",
    "tool_chain = llm_with_tools | JsonOutputToolsParser()\n",
    "tool_chain.invoke(\"what's 3 * 12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는 원래의 피단틱 클래스로 돌아갈 수도 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Multiply(a=3, b=12)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "\n",
    "tool_chain = llm_with_tools | PydanticToolsParser(tools=[Multiply])\n",
    "tool_chain.invoke(\"what's 3 * 12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특정 도구가 강제로 사용되도록(그리고 한 번만 사용되도록) 하려면 tool_choice 인수를 설정하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_w5nfVv8FpgsL9VIyQTMj09qv', 'function': {'arguments': '{\"a\":5,\"b\":10}', 'name': 'Multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 78, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_4f0b692a78', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_multiply = llm.bind_tools([Multiply], tool_choice=\"Multiply\")\n",
    "llm_with_multiply.invoke(\n",
    "    \"make up some numbers if you really want but I'm not forcing you\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰 사용량 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 28\n",
      "\tPrompt Tokens: 12\n",
      "\tCompletion Tokens: 16\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $4.9999999999999996e-05\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me a funny joke\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM\n",
    "- LLM은 LangChain의 핵심 구성 요소입니다.\n",
    "- LangChain은 OpenAI, Cohere, Hugging Face 등에서 제공하는 다양한 LLM과 상호 작용하기 위한 표준 인터페이스를 제공합니다.\n",
    "  \n",
    "- LLM은 랭체인 표현식 언어(LCEL)의 기본 빌딩 블록인 Runnable  인터페이스를 구현합니다.\n",
    "- 즉, invoke, ainvoke, stream, astream, batch, abatch, astream_log 호출을 지원합니다.\n",
    "- LLM은 문자열을 입력으로 받거나 List[BaseMessage] 및 PromptValue와 같이 문자열 프롬프트로 강제 변환할 수 있는 객체를 입력으로 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. 필립스 곡선 (Phillips Curve)\\n필립스 곡선은 뉴질랜드의 경제학자 알반 필립스가 1958년에 발표한 이론으로, 실업률과 물가 상승률 사이의 역관계를 설명하는 곡선이다. 이론에 따르면, 실업률이 낮을수록 임금이 상승하고 생산성이 증가하므로 물가 상승률이 높아지는 경향이 있다.\\n\\n2. 나이어보-데미지 모델 (Nairu-Damage Model)\\n나이어보-데미지 모델은 미국의 경제학자 데미지와 나이어보가 제시한 이론으로, 실업률이 자연실업률보다 높은 경우 장'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\n",
    "    \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 필립스 곡선 (Phillips Curve) 이론\n",
      "- 뉴질랜드 출신 경제학자 알번 윌리엄 필립스가 제안한 이론으로, 물가상승률과 실업률 사이의 관계를 설명한다. 이 이론에 따르면 실업률이 낮으면 임금 상승률이 높아지고 이는 물가 상승률을 야기한다.\n",
      "\n",
      "2. 자연유리실업률 이론 (Natural Rate of Unemployment Theory)\n",
      "- 미국의 경제학자 에드워드 프레스콧과 노벨 경제학자 로버트 뫼디글리아니가 제안한 이론으로, 실업률이 자연유리실업률 이하로 유지되면 인플레이션은"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\n",
    "    \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. 필립스 곡선 (Phillips Curve)\\n필립스 곡선은 뉴질랜드의 경제학자 알반 필립스가 1958년에 발표한 이론으로, 실업률과 물가 상승률 사이의 역관계를 설명하는 곡선이다. 이론에 따르면, 실업률이 낮을수록 임금이 상승하고 생산성이 증가하므로 물가 상승률이 높아지는 경향이 있다.\\n\\n2. 나이어보-데미지 모델 (Nairu-Damage Model)\\n나이어보-데미지 모델은 미국의 경제학자 데미지와 나이어보가 제시한 이론으로, 실업률이 자연실업률보다 높은 경우 장'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm.ainvoke(\n",
    "    \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 필립스 곡선 (Phillips Curve) 이론\n",
      "- 이론의 개요: 이론은 뉴질랜드의 경제학자 윌리엄 필립스에 의해 제안된 것으로, 실업률과 물가 상승률 사이에 반비례 관계가 있다는 것을 설명한다. 즉, 실업률이 낮으면 물가 상승률이 높아지고, 실업률이 높으면 물가 상승률이 낮아지는 경향을 보인다는 것이다. 이는 실업률이 높을 때 노동자들의 협상력이 약해지고 임금이 낮아지기 때문에 생산비용이 낮아지고, 그 결과로 물가 상승률이 낮아지는 것으로 설명된다.\n",
      "\n",
      "2. 자연"
     ]
    }
   ],
   "source": [
    "async for chunk in llm.astream(\n",
    "    \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n1. 필립스 곡선 (Phillips Curve)\\n필립스 곡선은 뉴질랜드의 경제학자 알반 필립스가 1958년에 발표한 이론으로, 실업률과 물가 상승률 사이의 역관계를 설명하는 곡선이다. 이론에 따르면, 실업률이 낮을수록 임금이 상승하고 생산성이 증가하므로 물가 상승률이 높아지는 경향이 있다.\\n\\n2. 나이어보-데미지 모델 (Nairu-Damage Model)\\n나이어보-데미지 모델은 미국의 경제학자 데미지와 나이어보가 제시한 이론으로, 실업률이 자연실업률보다 높은 경우 장']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm.abatch(\n",
    "    [\n",
    "        \"실업률과 인플레이션의 관계에 대한 이론에는 어떤 것이 있나요?\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output parsers\n",
    "- Output parser(출력 구문 분석기)로 언어모델의 텍스트 출력을 구조화 합니다.\n",
    "- Output parser에는 다음과 같은 몇 가지 주요 유형이 있습니다:\n",
    "- LLM의 텍스트를 구조화된 정보(예: JSON)로 변환\n",
    "- ChatMessage를 단순한 문자열로 변환\n",
    "- 메시지 외에 호출에서 반환된 추가 정보(예: OpenAI 함수 호출)를 문자열로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "output_parser.parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1903-10-29T13:23:14.114723Z, 1137-06-22T20:20:35.995796Z, 0426-12-12T21:21:42.127985Z\\n\\nReturn ONLY this string, no other words!\"}, template='Answer the users question:\\n\\n{question}\\n\\n{format_instructions}')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-01-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | OpenAI() | output_parser\n",
    "output = chain.invoke({\"question\": \"when was bitcoin founded?\"})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pydantic parser\n",
    "- 사용자가 임의의 Pydantic Model을 지정하고 해당 스키마를 준수하는 출력을 위해 LLM을 쿼리할 수 있다.\n",
    "- Pydantic은 이터 유효성 검사와 구조화된 데이터를 파싱하기 위한 라이브러리입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | model\n",
    "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})\n",
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LCEL\n",
    "- Output parser는 [LCEL, LangChain Expression Language](https://python.langchain.com/docs/expression_language/) 기본 구성 요소인  [Runnable interface](https://python.langchain.com/docs/expression_language/interface) 를 구현합니다.\n",
    "- 즉, invoke, ainvoke, stream, astream, batch, abatch, astream_log 호출을 지원합니다.\n",
    "- Output parser는 문자열 또는 BaseMessage를 입력으로 받아들이며 임의의 유형을 반환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output parser를 수동으로 호출하는 대신 Runnable 시퀀스에 추가할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 파서가 스트리밍 인터페이스를 지원하지만, 특정 파서만 부분적으로 파싱된 객체를 통해 스트리밍할 수 있는데,   \n",
    "이는 출력 유형에 따라 크게 달라지기 때문입니다. 부분 객체를 구성할 수 없는 파서는 단순히 완전히 파싱된 출력을 생성합니다.  \n",
    "    \n",
    "\t\n",
    "예를 들어 SimpleJsonOutputParser는 부분 출력을 통해 스트리밍할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    ")\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "json_chain = json_prompt | model | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'answer': ''},\n",
       " {'answer': '안'},\n",
       " {'answer': '안토'},\n",
       " {'answer': '안토니'},\n",
       " {'answer': '안토니 반'},\n",
       " {'answer': '안토니 반 레'},\n",
       " {'answer': '안토니 반 레웨'},\n",
       " {'answer': '안토니 반 레웨른'},\n",
       " {'answer': '안토니 반 레웨른후'},\n",
       " {'answer': '안토니 반 레웨른후크'},\n",
       " {'answer': '안토니 반 레웨른후크가'},\n",
       " {'answer': '안토니 반 레웨른후크가 현'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을 발'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을 발명'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을 발명했습니다'},\n",
       " {'answer': '안토니 반 레웨른후크가 현미경을 발명했습니다.'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(json_chain.stream({\"question\": \"누가 현미경을 누가 발명했나요?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
