{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMUrWfETCvXg"
   },
   "source": [
    "# LangChain Quickstart\n",
    "- Code 출처 : https://python.langchain.com/docs/get_started/quickstart \n",
    "- 수정사항 : 설명과 프롬프트 내용을 한글로 변경 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### langchain-openai 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI_API_KEY API KEY를 환경변수에 등록 \n",
    "- API Key :  https://platform.openai.com/api-keys\n",
    "- Command Prompt/Termial 에서 아래 명렁어 실행 : `Ctrl + ` \n",
    "    - Windows : setx OPENAI_API_KEY=\"...\"\n",
    "    - macOS, Linux : export OPENAI_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your OpenAI API key if not set as env var>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith는 텍스트 데이터를 생성하고 분석하는 데 도움을 줄 수 있습니다. 특히 텍스트 데이터를 사용하는 자연어 처리나 기계 학습 모델을 개발하는 경우에 유용하게 사용할 수 있습니다. 예를 들어, Langsmith를 사용하여 테스트 데이터를 생성하거나 텍스트 데이터를 전처리하고 분석하는 데 도움을 받을 수 있습니다. 또한 Langsmith를 사용하여 텍스트 분류, 감성 분석, 문서 요약 등과 같은 자연어 처리 작업을 수행할 수 있습니다. 따라서 Langsmith는 다양한 텍스트 기반 테스트 작업에 도움을 줄 수 있는 유용한 도구입니다.', response_metadata={'token_usage': {'completion_tokens': 216, 'prompt_tokens': 32, 'total_tokens': 248}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_fa89f7a861', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"langsmith가 어떻게 테스트에 도움을 줄 수 있나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt template : 사용자 입력을 LLM에 더 나은 입력으로 변환하는 데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "x0nefArFCvXi"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 세계적인 수준의 기술 문서 작성자입니다.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### llm과 prompt를 간단한 LLM chain으로 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith는 다양한 방법으로 테스트에 도움을 줄 수 있습니다. 일반적인 방법으로는 다음과 같은 것들이 있습니다:\\n\\n1. 다국어 지원 테스트: Langsmith는 다국어 환경에서의 테스트를 지원할 수 있습니다. 여러 언어로 된 텍스트를 생성하거나 번역할 수 있어, 다국어 웹사이트나 애플리케이션의 다국어 지원 기능을 효과적으로 테스트할 수 있습니다.\\n\\n2. 로컬리제이션 테스트: Langsmith는 로컬리제이션 테스트를 지원할 수 있습니다. 다양한 언어 및 지역 설정에서 텍스트를 생성하여, 로컬리제이션된 애플리케이션의 품질을 검증할 수 있습니다.\\n\\n3. 자연어 처리 테스트: Langsmith는 자연어 처리 기술을 활용하여 자연어 이해(Natural Language Understanding)나 자연어 생성(Natural Language Generation) 기능을 테스트하는 데 활용될 수 있습니다.\\n\\n4. 텍스트 분석 및 감정 분석: Langsmith는 텍스트 분석과 감정 분석 기능을 제공하여, 텍스트 데이터를 분석하고 감정을 파악하는 데 도움을 줄 수 있습니다.\\n\\n5. 자동화된 테스트: Langsmith를 활용하여 자동화된 테스트를 수행할 수 있습니다. 특히 반복적이고 대량의 텍스트 테스트를 효율적으로 처리할 수 있습니다.\\n\\n이러한 기능들을 통해 Langsmith는 다양한 테스트 시나리오에 유용하게 활용될 수 있습니다.', response_metadata={'token_usage': {'completion_tokens': 492, 'prompt_tokens': 60, 'total_tokens': 552}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_4f0b692a78', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"langsmith가 어떻게 테스트에 도움을 줄 수 있나요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 채팅 Message를 문자열로 변환하는 간단한 OutputParser를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith는 다양한 방법으로 테스트를 돕을 수 있습니다. 몇 가지 예시는 다음과 같습니다:\\n\\n1. **테스트 자동화**: langsmith는 테스트 자동화 스크립트를 작성하고 실행하여 소프트웨어의 기능을 효율적으로 테스트할 수 있습니다. 이를 통해 테스트의 반복 작업을 줄이고 테스트 커버리지를 향상시킬 수 있습니다.\\n\\n2. **테스트 케이스 작성**: langsmith는 테스트 케이스를 작성하여 테스트의 범위와 목적을 명확히 할 수 있습니다. 이를 통해 테스트의 일관성과 완전성을 유지할 수 있습니다.\\n\\n3. **버그 리포팅**: langsmith는 테스트 중 발견된 버그를 상세히 문서화하고 버그 리포트를 작성할 수 있습니다. 이를 통해 개발팀이 버그를 신속하게 수정할 수 있습니다.\\n\\n4. **테스트 전략 수립**: langsmith는 테스트 전략을 수립하고 테스트 계획을 작성하는 데 도움을 줄 수 있습니다. 이를 통해 테스트 프로세스를 효율적으로 관리하고 테스트의 품질을 향상시킬 수 있습니다.\\n\\n5. **성능 테스트**: langsmith는 소프트웨어의 성능을 측정하고 분석하여 성능 문제를 식별할 수 있습니다. 이를 통해 소프트웨어의 성능을 향상시키는 데 도움을 줄 수 있습니다.\\n\\n이러한 방법들을 통해 langsmith는 테스트 프로세스를 지원하고 소프트웨어의 품질을 향상시킬 수 있습니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"input\": \"langsmith가 어떻게 테스트에 도움을 줄 수 있나요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval Chain\n",
    "- 질문에 제대로 답하려면 추가 컨텍스트를 제공해야 합니다. Retrieval을 통해 이를 수행할 수 있습니다. \n",
    "- Retrieval(검색)은 LLM에 직접 전달하기에는 너무 많은 데이터가 있을 때 유용합니다. \n",
    "- 관련 데이터에서 Retriever를 사용하여 가장 관련성이 높은 부분만 가져와서 프롬프트에 전달합니다. \n",
    "- 아래 코드는 벡터스토어에 데이터를 저장한 후, 이를 검색하는 예제입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoup을 설치하고, WebBaseLoader로 웹페이지 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터를 임베딩벡터로 변환하고 벡터스토어로 색인화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# FAISS(Fast Approximate Nearest Neighbor Search) 설치\n",
    "%pip install -qU faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"제공된 context에만 근거하여 다음 질문에 답하세요.:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith를 사용하면 테스트 결과를 시각화할 수 있어서, 테스트 결과를 더 쉽게 이해하고 분석할 수 있어 도움을 줄 수 있습니다. 결과적으로 효율적으로 테스트를 수행하고 개선할 수 있는 방향을 찾을 수 있습니다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"LangSmith가 어떻게 테스트에 도움을 줄 수 있나요?\",\n",
    "    \"context\": [Document(page_content=\"LangSmith를 사용하면 테스트 결과를 시각화할 수 있습니다.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith는 디버깅, 테스트, 평가, 모니터링을 위한 플랫폼으로, 무엇이든지 LLM 프레임워크로 작성된 체인과 지능적인 에이전트를 구축할 수 있도록 도와줍니다. LangSmith는 사용자가 LLM 응용프로그램 수명주기 각 단계에서 지원하는 워크플로우에 대해 배울 수 있는 사용자 가이드와 함께 각 단계에서 신속히 시작할 수 있는 트레이싱과 평가를 제공합니다. 따라서 LangSmith를 사용하여 테스트를 수행하고 결과를 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"LangSmith가 어떻게 테스트에 도움을 줄 수 있나요?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conversation Retrieval Chain\n",
    "- LLM 주요 애플리케이션인 채팅봇 구현시에는 대화 히스토리를 고려해야 합니다.\n",
    "- create_retrieval_chain 함수 사용시 2가지를 변경해야 합니다:\n",
    "    - 검색 방법은 이제 가장 최근의 입력만 처리하는 것이 아니라 전체 히스토리를 고려해야 합니다.  \n",
    "    - 최종 LLM 체인도 마찬가지로 전체 히스토리를 고려해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Retrieval  \n",
    "- 검색을 업데이트하기 위해 새 체인을 생성합니다.  \n",
    "- 이 체인은 가장 최근의 입력(input)과 대화 기록(chat_history)을 받아 LLM을 사용하여 검색 쿼리를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 후속 질문을 하여 이를 테스트해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Introduction', 'language': 'en'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?\"),\n",
    "    AIMessage(content=\"예!\"),\n",
    "]\n",
    "\n",
    "retriever_chain.invoke({\"chat_history\": chat_history, \"input\": \"방법을 알려주세요.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이렇게 하면 LangSmith에서 테스트에 대한 문서가 반환되는 것을 볼 수 있습니다. \n",
    "- 이는 LLM이 채팅 히스토리와 후속 질문을 결합하여 새로운 쿼리를 생성했기 때문입니다.\n",
    "- 이제 새로운 retriever가 생겼으니 검색된 문서를 염두에 두고 대화를 계속할 수 있는 새로운 체인을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End-to-end로 테스트할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?'),\n",
       "  AIMessage(content='예!')],\n",
       " 'input': '방법을 알려주세요.',\n",
       " 'context': [Document(page_content=\"LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Introduction', 'language': 'en'})],\n",
       " 'answer': 'LangSmith를 사용하여 LLM 애플리케이션을 테스트하려면 다음 단계를 따르세요:\\n\\n1. 먼저 Tracing Quick Start를 통해 추적 설정을 시작합니다.\\n2. 그런 다음 Evaluation Quick Start를 통해 평가 설정을 시작합니다.\\n\\n더 자세한 정보를 얻으려면 User Guide 섹션을 확인하고, 계정 생성, API 키 획득, 환경 구성 방법을 배우세요. Tracing 및 Evaluation 능력에 대한 자세한 내용도 확인할 수 있습니다.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?\"),\n",
    "    AIMessage(content=\"예!\"),\n",
    "]\n",
    "\n",
    "retrieval_chain.invoke({\"chat_history\": chat_history, \"input\": \"방법을 알려주세요.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent\n",
    "- Agent는 LLM이 수행할 단계를 결정합니다.\n",
    "- Agent를 만들 때 Agent가 액세스할 수 있는 도구(Tool)을 정합니다.\n",
    "- 이 예에서는 에이전트에게 2개의 Tool에 대한 액세스 권한을 부여하겠습니다:\n",
    "    1. 방금 만든 Retriever : LangSmith에 대한 질문에 답변\n",
    "    2. 검색 도구(Search tool) : 최신 정보가 필요한 질문에 답변  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever를 위한 툴을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search를 위한 툴 설정\n",
    "- Search 엔진으로 Tavily 사옹 : API Key - https://app.tavily.com/\n",
    "- export TAVILY_API_KEY=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"<your Tavily API key if not set as env var>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 미리 정의된 프롬프트를 사용하기 위해 langchain hub 설치\n",
    " https://smith.langchain.com/hub/  \n",
    " https://smith.langchain.com/hub/hwchase17/openai-functions-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__b65e9f75a6b74a72ad48df022821e1ce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent를 호출하고 Agent의 응답을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'How can LangSmith help with tests?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith는 프로덕션급 LLM 애플리케이션을 구축하기 위한 플랫폼입니다. LangSmith를 사용하면 어떤 LLM 프레임워크로 구축된 체인 및 지능적 에이전트를 디버깅, 테스트, 평가 및 모니터링할 수 있습니다. 또한 LangSmith는 LangChain과 원활하게 통합되어 있습니다. LangSmith를 사용하면 트레이싱, 평가, 프록시 등 다양한 기능을 활용할 수 있습니다. 자세한 내용은 LangSmith 문서를 참고하시기 바랍니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmith가 테스트에 어떤 도움을 줄 수 있나요?',\n",
       " 'output': 'LangSmith는 프로덕션급 LLM 애플리케이션을 구축하기 위한 플랫폼입니다. LangSmith를 사용하면 어떤 LLM 프레임워크로 구축된 체인 및 지능적 에이전트를 디버깅, 테스트, 평가 및 모니터링할 수 있습니다. 또한 LangSmith는 LangChain과 원활하게 통합되어 있습니다. LangSmith를 사용하면 트레이싱, 평가, 프록시 등 다양한 기능을 활용할 수 있습니다. 자세한 내용은 LangSmith 문서를 참고하시기 바랍니다.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"LangSmith가 테스트에 어떤 도움을 줄 수 있나요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': '오늘 서울 날씨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.accuweather.com/ko/kr/seoul/1-226081_30_al/hourly-weather-forecast/1-226081_30_al', 'content': '서울의 오늘 날씨는 맑고 밝고 충분한 날이며, 최고 기온은 17°C, 최저 기온은 2°C입니다. 바람은 서북서로 10~25미/h로 강하고, 대기질은 보통이며,'}, {'url': 'https://www.weather.go.kr/w/index.do', 'content': '기상청 날씨누리. 전국특보 없음. 밀물·썰물 정보 해와 달이 뜨고지는 시간 기후정보포털 기상자료 개방포털 기상기후 빅데이터 대기질 예·경보 날씨해설 (유튜브) 기상청 행정누리집 산악날씨 한강홍수통제소 해양기상 정보포털 항공기상청. 아이콘, 설명으로 ...'}, {'url': 'https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081', 'content': '서울시는 오늘 2월 19일 저녁에 뇌우가 내리고 최저 온도는 32°F입니다. 밤에는 흐리고 바람이 강하며, 밤사이 해와 달은 10시간 57분'}, {'url': 'https://www.accuweather.com/ko/kr/seoul/226081/hourly-weather-forecast/226081', 'content': '서울시에서 오늘 오전 7시부터 오후 11시까지는 비가 내리고 습도가 높고 대기질이 나쁨입니다. 오후 11시부터는 비가 멈고 구름이 덮이고 최고 기온은 54도, 최저 기온은 43도입니다.'}, {'url': 'https://weather.com/ko-KR/weather/today/l/82e46175f97c224acf6b95afc4934fbae0e4ba123adcee8a52b7be97c303467b', 'content': '서울특별시 날씨 예보 오늘 시간별 일별 아침 6° -- 오후 12° -- 저녁 5° 1% 밤새 3° 16% Sponsored Content 오늘 서울특별시의 날씨 예보 체감온도9° 06:38 18:42 최고/최저 -- / 2° 바람 10 km/h 습도 15% 이슬점 -16°'}]\u001b[0m\u001b[32;1m\u001b[1;3m서울의 오늘 날씨는 맑고 밝고 충분한 날이며, 최고 기온은 17°C, 최저 기온은 2°C입니다. 바람은 서북서로 10~25미/h로 강하고, 대기질은 보통입니다. 오늘은 상쾌한 하루가 될 것으로 보입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '오늘 서울 날씨는?',\n",
       " 'output': '서울의 오늘 날씨는 맑고 밝고 충분한 날이며, 최고 기온은 17°C, 최저 기온은 2°C입니다. 바람은 서북서로 10~25미/h로 강하고, 대기질은 보통입니다. 오늘은 상쾌한 하루가 될 것으로 보입니다.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"오늘 서울 날씨는?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'LLM 애플리케이션 테스트 도와줄 방법'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith는 LLM 애플리케이션을 디버깅, 테스트, 평가 및 모니터링할 수 있는 플랫폼입니다. LangSmith를 사용하여 LLM 프레임워크로 구축된 체인 및 지능적 에이전트를 손쉽게 통합할 수 있습니다. LangSmith는 LangChain의 개발사인 LangChain에 의해 개발되었습니다.\n",
      "\n",
      "LangSmith를 사용하여 다음과 같은 작업을 수행할 수 있습니다:\n",
      "- 디버깅\n",
      "- 테스트\n",
      "- 평가\n",
      "- 모니터링\n",
      "\n",
      "더 자세한 정보를 얻으려면 LangSmith의 사용자 가이드를 확인하시기 바랍니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?'),\n",
       "  AIMessage(content='예!')],\n",
       " 'input': '방법을 알려주세요.',\n",
       " 'output': 'LangSmith는 LLM 애플리케이션을 디버깅, 테스트, 평가 및 모니터링할 수 있는 플랫폼입니다. LangSmith를 사용하여 LLM 프레임워크로 구축된 체인 및 지능적 에이전트를 손쉽게 통합할 수 있습니다. LangSmith는 LangChain의 개발사인 LangChain에 의해 개발되었습니다.\\n\\nLangSmith를 사용하여 다음과 같은 작업을 수행할 수 있습니다:\\n- 디버깅\\n- 테스트\\n- 평가\\n- 모니터링\\n\\n더 자세한 정보를 얻으려면 LangSmith의 사용자 가이드를 확인하시기 바랍니다.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?\"),\n",
    "    AIMessage(content=\"예!\"),\n",
    "]\n",
    "agent_executor.invoke({\"chat_history\": chat_history, \"input\": \"방법을 알려주세요.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Serving with LangServe\n",
    "#### langserve, fastapi를 설치하고 로컬시스템 터미널에서 다음 명령으로 실행합니다.\n",
    "#### `py311\\Scripts\\activate`  또는 `source py311/bin/activate` \n",
    "#### `cd code`        \n",
    "#### `python server.py`    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langserve fastapi sse_starlette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 노트북에서 아래 코드를 실행하지 마세요.  \n",
    "#### server.py 파일의 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from typing import List\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langserve import add_routes\n",
    "\n",
    "\n",
    "# 1. Load Retriever\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "\n",
    "# 2. Create Tools\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")\n",
    "search = TavilySearchResults()\n",
    "tools = [retriever_tool, search]\n",
    "\n",
    "\n",
    "# 3. Create Agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# 4. App definition\n",
    "app = FastAPI(\n",
    "    title=\"LangChain Server\",\n",
    "    version=\"1.0\",\n",
    "    description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Adding chain route\n",
    "\n",
    "# We need to add these input/output schemas because the current AgentExecutor\n",
    "# is lacking in schemas.\n",
    "\n",
    "class Input(BaseModel):\n",
    "    input: str\n",
    "    chat_history: List[BaseMessage] = Field(\n",
    "        ...,\n",
    "        extra={\"widget\": {\"type\": \"chat\", \"input\": \"location\"}},\n",
    "    )\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    output: str\n",
    "\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    agent_executor.with_types(input_type=Input, output_type=Output),\n",
    "    path=\"/agent\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playground\n",
    "- http://localhost:8000/agent/playground/ 접속\n",
    "- Input : LangSmith 가 테스트를 어떻게 도와줄 수 있나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'LangSmith는 다양한 주제에 대한 정보를 제공하고, 검색을 통해 필요한 정보를 찾아주는 도구입니다. 또한 LangSmith를 통해 특정 주제에 대한 질문에 대한 답변을 얻을 수도 있습니다. LangSmith를 활용하여 원하는 정보를 빠르게 찾아보세요!'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/agent/\")\n",
    "remote_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"LangSmith 가 테스트를 어떻게 도와줄 수 있나요?\",\n",
    "        \"chat_history\": [],  # Providing an empty list as this is the first call\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 생성형 AI 활용 실습  \n",
    "- 1. server.py 코드 설명   \n",
    "- 2. server.py 코드 리뷰\n",
    "- 3. server.py 코드 리팩토링\n",
    "- 4. server.py 주석 추가"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
