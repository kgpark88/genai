{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMUrWfETCvXg"
   },
   "source": [
    "# LangChain Quickstart\n",
    "- Code 출처 : https://python.langchain.com/docs/get_started/quickstart \n",
    "- 수정사항 : 설명과 프롬프트 내용을 한글로 변경 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ModuleNotFoundError: No module named 'pwd' 에러 발생시에는 langchain-community==0.0.19 설치\n",
    "%pip install -qU langchain langchain-community langchain-openai langchain-anthropic cohere llama-index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI_API_KEY API KEY를 환경변수에 등록 \n",
    "- API Key :  https://platform.openai.com/api-keys\n",
    "- Command Prompt/Termial 에서 아래 명렁어 실행 : `Ctrl + ` \n",
    "    - Windows : setx OPENAI_API_KEY=\"...\"\n",
    "    - macOS, Linux : export OPENAI_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTHROPIC API KEY를 환경변수에 등록 \n",
    "- API Key :  https://console.anthropic.com/settings/keys\n",
    "- Command Prompt/Termial 에서 아래 명렁어 실행 : `Ctrl + ` \n",
    "    - Windows : setx ANTHROPIC_API_KEY=\"...\"\n",
    "    - macOS, Linux : export ANTHROPIC_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COHERE_API_KEY API KEY를 환경변수에 등록 \n",
    "- API Key :  https://dashboard.cohere.com/api-keys\n",
    "- Command Prompt/Termial 에서 아래 명렁어 실행 : `Ctrl + ` \n",
    "    - Windows : setx COHERE_API_KEY=\"...\"\n",
    "    - macOS, Linux : export COHERE_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"COHERE_API_KEY\"] = \"your COHERE_API_KEY API key if not set as env var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatCohere\n",
    "\n",
    "# llm = ChatCohere(cohere_api_key=\"...\")\n",
    "llm = ChatCohere()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원하는 LLM을 설치하고 초기화했으면 이제 사용해 볼 수 있습니다!   \n",
    "학습 데이터에 없던 것이므로 그다지 좋은 response가 나오지 않을 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith는 여러 가지 방식으로 테스트 프로세스에 도움이 될 수 있습니다. \\n\\n1. 자동화 : Langsmith는 테스트 케이스를 실행하고, 테스트 데이터를 생성하고, 테스트 결과를 기록하는 등 반복적이고 지루한 테스트 작업의 자동화를 도울 수 있습니다. 이것은 테스트 팀이 더 효율적이고 정확하게 일할 수 있게 해주며, 수동 테스트에 소요되는 시간을 줄여 줍니다. \\n\\n2. 테스트 데이터 생성 : Langsmith는 다양한 테스트 데이터를 생성하는 데 도움이 될 수 있습니다. 예를 들어, Langsmith는 테스트 케이스를 위해 다양한 입력 scenario를 생성할 수 있으며, 이는 테스트 커버리지를 개선하고 테스트의 질을 높여주는 데 도움이 됩니다. \\n\\n3. 테스트 케이스 설계 : Langsmith는 테스트 케이스를 설계하는 과정도 도울 수 있습니다. 테스트 팀이 테스트 케이스를 더 효과적으로 설계하고, 결함이 있는 경우나 일반적인 사용 사례를 더 잘 커버할 수 있게 해주는 추천을 할 수 있습니다. \\n\\n4. 문서화 : Langsmith는 테스트 계획, 테스트 케이스 및 테스트 결과와 같은 테스트 관련 문서의 생성 및 업데이트를 자동화하여 문서화 프로세스를 도울 수 있습니다. 이것은 테스트 팀의 업무 효율성을 높여주고, 다른 팀원들과의 커뮤니케이션을 개선하는 데 도움이 됩니다. \\n\\n5. 지속적인 통합 및 지속적인 배포(CI/CD) : Langsmith는 CI/CD 프로세스에 통합되어 테스트를 자동으로 실행하고, 테스트 결과에 따라 배포를 승인 또는 거부할 수 있습니다. 이것은 테스트가 코드의 변경사항과 함께 자주 실행되도록 보장하여 소프트웨어의 품질을 개선하는 데 도움이 됩니다. \\n\\n6. 회고록 분석 : Langsmith는 테스트 로그를 분석하여 패턴과 이상치를 식별하고, 테스트 관련 문제에 대한 통찰력을 제공할 수 있습니다. 예를 들어, Langsmith는 특정 테스트 케이스에서 실패의 경향을 식별하거나, 테스트 성능 문제점을 식별하여 테스트 프로세스의 효율성을 개선하는 데 도움이 될 수 있습니다. \\n\\n전체적으로, Langsmith는 테스트 프로세스의 효율성과 효과성을 높여주고, 테스트 팀의 생산성을 높여주는 테스트 자동화 및 지원 도구로 테스트에 큰 도움을 줄 수 있습니다.', response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'token_count': {'prompt_tokens': 79, 'response_tokens': 489, 'total_tokens': 568, 'billed_tokens': 502}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"langsmith가 어떻게 테스트에 도움을 줄 수 있나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt template : 사용자 입력을 LLM에 더 나은 입력으로 변환하는 데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x0nefArFCvXi"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 세계적인 수준의 기술 문서 작성자입니다.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### llm과 prompt를 간단한 LLM chain으로 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith는 테스트 프로세스에 여러 가지 방식으로 도움을 줄 수 있습니다. \\n\\n1. 자동화 테스트: Langsmith는 테스트 케이스를 자동으로 실행하고 테스트 결과를 기록하는 자동화 테스트 스크립트의 생성을 지원할 수 있습니다. 이것은 테스트 프로세스의 효율성을 높이고 인간 오류의 가능성을 줄여 줍니다. \\n\\n2. 테스트 케이스 생성: Langsmith는 테스트 케이스를 생성하고 문서화하는 것을 도울 수 있습니다. 이것은 테스트 커버리지를 개선하고 테스트 프로세스의 일관성을 보장하는 데 도움이 될 수 있습니다. \\n\\n3. 테스트 데이터 관리: Langsmith는 테스트 데이터의 생성과 관리를 돕고, 테스트에 필요한 다양한 입력 값과 기대값을 제공할 수 있습니다. 이것은 데이터가 많은 테스트 scenario에서 특히 유용합니다. \\n\\n4. 테스트 계획 및 조직: Langsmith는 테스트 계획 및 테스트 케이스 우선 순위 결정에 도움을 줄 수 있습니다. 위험 기반 테스트 접근 방식을 사용하면 가장 중요한 테스트 케이스에 집중할 수 있게 해 줍니다. \\n\\n5. 수동 테스트의 효율성 향상: Langsmith는 수동 테스트 프로세스의 효율성을 높이기 위해 테스트 담당자가 테스트 케이스를 더 빠르고 정확하게 실행할 수 있도록 도울 수 있는 도구들을 제공할 수 있습니다. \\n\\n6. 지속적인 통합 및 지속적인 배포(CI/CD) 프로세스와의 통합: Langsmith는 CI/CD 프로세스에 통합되어 자동으로 테스트를 실행하고, 테스트 결과에 따라 배포를 승인 또는 거부할 수 있습니다. 이것은 소프트웨어의 품질을 보장하고 배포 프로세스를 원활하게 하는 데 도움이 될 수 있습니다. \\n\\n7. 결함 추적 및 관리: Langsmith는 결함 추적 시스템과 통합되어 결함을 신속하게 보고하고 관리할 수 있습니다. 이것은 결함 해결 프로세스의 효율성을 높이고 테스트팀이 결함의 상태를 추적하는 데 도움이 될 수 있습니다. \\n\\n전체적으로 Langsmith는 테스트 프로세스의 효율성과 효과를 높이기 위해 다양한 도구들과 기능을 제공하여 테스트에 도움을 줄 수 있습니다.', response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'token_count': {'prompt_tokens': 94, 'response_tokens': 444, 'total_tokens': 538, 'billed_tokens': 469}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"langsmith가 어떻게 테스트에 도움을 줄 수 있나요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 채팅 Message를 문자열로 변환하는 간단한 OutputParser를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith는 테스트 프로세스에 여러 가지 방식으로 도움을 줄 수 있습니다. \\n\\n- 테스트 데이터 생성: Langsmith는 다양한 언어의 테스트 데이터를 생성하는 데 도움이 될 수 있습니다. 예를 들어, 문법이나 언어적 패턴이 올바른 문장을 생성하도록 설계할 수 있습니다. 이렇게 생성된 데이터는 테스트 케이스를 채우거나 언어에 특화된 테스트 시나리오를 만들 때 사용됩니다. \\n\\n- 로컬라이제이션 테스트: Langsmith는 응용 프로그램을 여러 언어로 번역하는 데 도움이 될 수 있으며, 이를 통해 로컬라이제이션 테스트를 수행할 수 있습니다. 개발자는 응용 프로그램이 다른 언어에서도 올바르게 작동하고 올바른 언어로 표시되는지 확인할 수 있습니다. \\n\\n- 자연어 처리 테스트: Langsmith는 자연어 처리(NLP) 테스트에 도움이 되는 도구와 기능을 제공할 수 있습니다. 예를 들어, 감정 분석, 단어의 고빈도 수 또는 문장 구조 분석과 같은 NLP 작업에서 테스트 데이터를 준비하는 것을 도울 수 있습니다. \\n\\n- 언어 테스트 자동화: Langsmith는 테스트 케이스를 자동화하여 반복적인 테스트 작업을 가속화하는 데 도움이 될 수 있습니다. 예를 들어, 테스트 스크립트를 실행하여 테스트 결과를 기록하고, 테스트를 위해 다른 언어 설정으로 응용 프로그램을 구성하는 등 테스트 환경을 설정하는 데 도움을 줄 수 있습니다. \\n\\n- 테스트 커버리지 분석: Langsmith는 코드의 언어적 측면에 대한 테스트 커버리지를 분석하는 데 도움이 될 수 있습니다. 특정 언어 구문이나 기능이 테스트에서 충분히 커버리지를 받는지 확인하여 테스트의 효과를 평가하는 데 도움을 줄 수 있습니다. \\n\\n- 번역 품질 테스트: 다국어 응용 프로그램에서 Langsmith는 번역의 정확성과 일관성을 테스트하는 데 도움이 될 수 있습니다. 같은 문장이 여러 언어에서 일관되게 번역되었는지 확인하는 등 번역 품질 테스트를 위해 테스트 케이스를 생성하는 데 도움을 줄 수 있습니다. \\n\\n요약하면, Langsmith는 테스트 데이터 생성, 로컬라이제이션 테스트, 자연어 처리 테스트의 자동화 및 효율화, 테스트 커버리지 분석 등 다양한 테스트 활동에 도움을 줄 수 있는 도구와 기능을 제공하여 테스트 프로세스를 개선하는 데 도움이 될 수 있습니다.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"input\": \"langsmith가 어떻게 테스트에 도움을 줄 수 있나요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval Chain\n",
    "- 질문에 제대로 답하려면 추가 컨텍스트를 제공해야 합니다. Retrieval을 통해 이를 수행할 수 있습니다. \n",
    "- Retrieval(검색)은 LLM에 직접 전달하기에는 너무 많은 데이터가 있을 때 유용합니다. \n",
    "- 관련 데이터에서 Retriever를 사용하여 가장 관련성이 높은 부분만 가져와서 프롬프트에 전달합니다. \n",
    "- 아래 코드는 벡터스토어에 데이터를 저장한 후, 이를 검색하는 예제입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoup을 설치하고, WebBaseLoader로 웹페이지 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터를 임베딩벡터로 변환하고 벡터스토어로 색인화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# FAISS(Fast Approximate Nearest Neighbor Search) 설치\n",
    "%pip install -qU faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"제공된 context에만 근거하여 다음 질문에 답하세요.:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith를 사용하면 테스트 결과를 시각화하여 이해하기 쉽고 해석하기 쉬운 형태로 만들 수 있습니다. 그래프, 차트 또는 다른 시각적 요소를 사용하여 테스트 결과의 중요성을 더 잘 이해할 수 있습니다.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"LangSmith가 어떻게 테스트에 도움을 줄 수 있나요?\",\n",
    "    \"context\": [Document(page_content=\"LangSmith를 사용하면 테스트 결과를 시각화할 수 있습니다.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith는 개발자가 디버깅하고, 테스트하고, 평가하고, 지능형 에이전트와 머신러닝 모델 체인(LLM framework로 구축됨)을 모니터링하는 것을 돕는 플랫폼입니다. LangSmith를 사용하면 이러한 모델을 구축하는 데 사용되는 LangChain과 같은 오픈 소스 프레임워크와 원활하게 통합하여 신속하게 실험하고 최적화할 수 있습니다. 따라서 LangSmith는 LLM 응용 프로그램의 테스트에 도움이 될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"LangSmith가 어떻게 테스트에 도움을 줄 수 있나요?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conversation Retrieval Chain\n",
    "- LLM 주요 애플리케이션인 채팅봇 구현시에는 대화 히스토리를 고려해야 합니다.\n",
    "- create_retrieval_chain 함수 사용시 2가지를 변경해야 합니다:\n",
    "    - 검색 방법은 이제 가장 최근의 입력만 처리하는 것이 아니라 전체 히스토리를 고려해야 합니다.  \n",
    "    - 최종 LLM 체인도 마찬가지로 전체 히스토리를 고려해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Retrieval  \n",
    "- 검색을 업데이트하기 위해 새 체인을 생성합니다.  \n",
    "- 이 체인은 가장 최근의 입력(input)과 대화 기록(chat_history)을 받아 LLM을 사용하여 검색 쿼리를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 후속 질문을 하여 이를 테스트해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"LangSmith | 🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | 🦜️🛠️ LangSmith', 'description': 'Introduction', 'language': 'en'})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?\"),\n",
    "    AIMessage(content=\"예!\"),\n",
    "]\n",
    "\n",
    "retriever_chain.invoke({\"chat_history\": chat_history, \"input\": \"방법을 알려주세요.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이렇게 하면 LangSmith에서 테스트에 대한 문서가 반환되는 것을 볼 수 있습니다. \n",
    "- 이는 LLM이 채팅 히스토리와 후속 질문을 결합하여 새로운 쿼리를 생성했기 때문입니다.\n",
    "- 이제 새로운 retriever가 생겼으니 검색된 문서를 염두에 두고 대화를 계속할 수 있는 새로운 체인을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End-to-end로 테스트할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?'),\n",
       "  AIMessage(content='예!')],\n",
       " 'input': '방법을 알려주세요.',\n",
       " 'context': [Document(page_content=\"LangSmith | 🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | 🦜️🛠️ LangSmith', 'description': 'Introduction', 'language': 'en'})],\n",
       " 'answer': 'LangSmith는 개발자가 LLM 응용 프로그램을 테스트하는 것을 돕는 데에 집중하는 플랫폼입니다. LangSmith를 사용하여 LLM 응용 프로그램을 테스트하려면 다음과 같은 방법을 사용할 수 있습니다: \\n\\n1. LangSmith 계정 만들기: LangSmith의 기능들을 사용하려면 먼저 계정을 만들어야 합니다. LangSmith 홈페이지에서 이메일 주소와 비밀번호를 입력하여 계정을 만들 수 있습니다.\\n\\n2. LangSmith 설정하기: 계정이 생성되면 LangSmith를 설정해야 합니다. 설정에는 API 키 생성, 환경 구성 등이 포함됩니다. LangSmith 문서의 \"설정\" 부분에서 자세한 지침을 확인할 수 있습니다.\\n\\n3. 테스트할 LLM 응용 프로그램 업로드: LangSmith로 이동하여 응용 프로그램의 코드를 업로드하십시오. LangSmith는 LangChain을 비롯하여 다양한 LLM framework와 함께 작동하도록 설계되었습니다.\\n\\n4. 평가 시작: 코드를 업로드한 후에는 LangSmith의 평가 기능을 사용하여 LLM 응용 프로그램을 테스트할 수 있습니다. 평가 기능은 응용 프로그램의 정확도, 성능, 행동 등을 평가하는 데 도움이 되는 다양한 도구와 기능을 제공합니다.\\n\\n5. 추적 및 모니터링: 응용 프로그램의 테스트를 실행하고 난 후에는 LangSmith의 추적 및 모니터링 기능을 사용하여 테스트 세션을 추적하고 모니터링할 수 있습니다. 이렇게 하면 응용 프로그램의 성능를 자세히 분석하고 필요한 조정을 할 수 있습니다.\\n\\n6. 평가 결과 확인: 테스트가 완료되면 LangSmith에서 제공되는 평가 결과를 확인할 수 있습니다. LangSmith는 응용 프로그램의 성능를 시각화하고 분석하는 데 도움이 되는 다양한 도구와 차트를 제공합니다. \\n\\n이 외에도 LangSmith는 LLM 응용 프로그램의 개발 프로세스 전체에서 도움이 되는 많은 기능과 도구를 제공합니다. 개발자는 LangSmith 문서의 \"User Guide\" 섹션에서 자세한 정보를 확인할 수 있습니다.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?\"),\n",
    "    AIMessage(content=\"예!\"),\n",
    "]\n",
    "\n",
    "retrieval_chain.invoke({\"chat_history\": chat_history, \"input\": \"방법을 알려주세요.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent - OpenAI API Key 필요\n",
    "- Agent는 LLM이 수행할 단계를 결정합니다.\n",
    "- Agent를 만들 때 Agent가 액세스할 수 있는 도구(Tool)을 정합니다.\n",
    "- 이 예에서는 에이전트에게 2개의 Tool에 대한 액세스 권한을 부여하겠습니다:\n",
    "    1. 방금 만든 Retriever : LangSmith에 대한 질문에 답변\n",
    "    2. 검색 도구(Search tool) : 최신 정보가 필요한 질문에 답변  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever를 위한 툴을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tavily(Search 엔진) API KEY를 환경변수에 등록 \n",
    "- API Key - https://app.tavily.com/  \n",
    "- Command Prompt/Termial 에서 아래 명렁어 실행 : `Ctrl + ` \n",
    "    - Windows : setx  TAVILY_API_KEY=\"...\"\n",
    "    - macOS, Linux : export TAVILY_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"<your Tavily API key if not set as env var>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 미리 정의된 프롬프트를 사용하기 위해 langchain hub 설치\n",
    " https://smith.langchain.com/hub/  \n",
    " https://smith.langchain.com/hub/hwchase17/openai-functions-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__b65e9f75a6b74a72ad48df022821e1ce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent를 호출하고 Agent의 응답을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'How can LangSmith help with tests?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction​LangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start​Tracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps​Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources​LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith는 테스트에 도움을 주는 플랫폼입니다. LangSmith를 사용하면 LLM(언어 모델) 프레임워크를 기반으로 구축된 체인 및 지능형 에이전트를 디버깅, 테스트, 평가 및 모니터링할 수 있습니다. LangSmith는 LangChain과 원활하게 통합되며, LangChain은 LLM과 함께 작업하기 위한 오픈 소스 프레임워크입니다. LangSmith를 사용하여 테스트를 수행하고 LLM 애플리케이션 라이프사이클의 각 단계에서 지원되는 워크플로우에 대해 알아볼 수 있습니다. 또한 LangSmith를 사용하여 추적 및 평가 기능을 활용할 수 있습니다. 자세한 내용은 LangSmith의 문서를 참조하시기 바랍니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmith가 테스트에 어떤 도움을 줄 수 있나요?',\n",
       " 'output': 'LangSmith는 테스트에 도움을 주는 플랫폼입니다. LangSmith를 사용하면 LLM(언어 모델) 프레임워크를 기반으로 구축된 체인 및 지능형 에이전트를 디버깅, 테스트, 평가 및 모니터링할 수 있습니다. LangSmith는 LangChain과 원활하게 통합되며, LangChain은 LLM과 함께 작업하기 위한 오픈 소스 프레임워크입니다. LangSmith를 사용하여 테스트를 수행하고 LLM 애플리케이션 라이프사이클의 각 단계에서 지원되는 워크플로우에 대해 알아볼 수 있습니다. 또한 LangSmith를 사용하여 추적 및 평가 기능을 활용할 수 있습니다. 자세한 내용은 LangSmith의 문서를 참조하시기 바랍니다.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"LangSmith가 테스트에 어떤 도움을 줄 수 있나요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': '서울 날씨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.weather.go.kr/w/index.do', 'content': '기상청 날씨누리는 전국의 날씨 예보, 특보, 기후정보, 대기질 정보 등을 제공하는 공식 웹사이트입니다. 서울 날씨는 홈 페이지 상단의 날씨 아이콘을 클릭하면'}, {'url': 'https://www.weather.go.kr/w/weather/forecast/mid-term.do?stnId1=109', 'content': '서울ㆍ인천ㆍ경기도. (강수) 28일 (목)은 비가 내리겠습니다. (기온) 이번 예보기간 아침 기온은 1~9도, 낮 기온은 12~20도로 평년 (최저기온 0~6도, 최고기온 12~17도)과 비슷하거나 높겠습니다. (해상) 서해중부해상의 물결은 0.5~2.0m로 일겠습니다. (주말전망) 30일 (토 ...'}, {'url': 'https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081', 'content': '서울시의 현재 날씨는 구름 조금이고 44°F, RealFeel® 39°F입니다. 밤에는 흐리고 뇌우 확률이 40%이며, 최저 온도는 32°F입니다.'}, {'url': 'https://weather.com/ko-KR/weather/today/l/82e46175f97c224acf6b95afc4934fbae0e4ba123adcee8a52b7be97c303467b', 'content': 'The Weather Channel 및 Weather.com이 제공하는 오늘과 오늘 밤 서울특별시 일기예보, 날씨 상태 및 도플러 레이더'}, {'url': 'https://www.accuweather.com/ko/kr/seoul/226081/hourly-weather-forecast/226081', 'content': '서울시에서 오늘 오전 7시부터 오후 11시까지는 비가 내리고 습도가 높고 대기질이 나쁨입니다. 오후 11시부터는 비가 멈고 구름이 덮이고 최고 기온은 54도, 최저 기온은 43도입니다.'}]\u001b[0m\u001b[32;1m\u001b[1;3m서울의 현재 날씨는 구름이 조금 있고 44°F이며 RealFeel® 온도는 39°F입니다. 밤에는 흐리고 뇌우 확률이 40%이며, 최저 온도는 32°F입니다. 자세한 정보는 [AccuWeather](https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081)에서 확인하실 수 있습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '오늘 서울 날씨는?',\n",
       " 'output': '서울의 현재 날씨는 구름이 조금 있고 44°F이며 RealFeel® 온도는 39°F입니다. 밤에는 흐리고 뇌우 확률이 40%이며, 최저 온도는 32°F입니다. 자세한 정보는 [AccuWeather](https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081)에서 확인하실 수 있습니다.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"오늘 서울 날씨는?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'How can LangSmith help with LLM application testing?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction​LangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start​Tracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps​Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources​LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith는 프로덕션급 LLM 애플리케이션을 구축하는 플랫폼입니다. LangSmith를 사용하면 어떤 LLM 프레임워크로 구축된 체인 및 지능형 에이전트를 디버깅, 테스트, 평가 및 모니터링할 수 있습니다. 또한 LangSmith는 LangChain과 원활하게 통합되어 있습니다. LangSmith를 사용하여 LLM 애플리케이션 테스트를 도와줄 수 있습니다. 자세한 내용은 LangSmith의 사용자 가이드를 참조하시기 바랍니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?'),\n",
       "  AIMessage(content='예!')],\n",
       " 'input': '방법을 알려주세요.',\n",
       " 'output': 'LangSmith는 프로덕션급 LLM 애플리케이션을 구축하는 플랫폼입니다. LangSmith를 사용하면 어떤 LLM 프레임워크로 구축된 체인 및 지능형 에이전트를 디버깅, 테스트, 평가 및 모니터링할 수 있습니다. 또한 LangSmith는 LangChain과 원활하게 통합되어 있습니다. LangSmith를 사용하여 LLM 애플리케이션 테스트를 도와줄 수 있습니다. 자세한 내용은 LangSmith의 사용자 가이드를 참조하시기 바랍니다.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmith가 LLM 애플리케이션 테스트를 도와줄 수 있나요?\"),\n",
    "    AIMessage(content=\"예!\"),\n",
    "]\n",
    "agent_executor.invoke({\"chat_history\": chat_history, \"input\": \"방법을 알려주세요.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Serving with LangServe\n",
    "#### langserve, fastapi를 설치하고 로컬시스템 터미널에서 다음 명령으로 실행합니다.\n",
    "#### `py311\\Scripts\\activate`  또는 `source py311/bin/activate` \n",
    "#### `cd code`        \n",
    "#### `python server.py`    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langserve fastapi sse_starlette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### server.py 파일의 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# from typing import List\n",
    "\n",
    "# from fastapi import FastAPI\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_community.embeddings import CohereEmbeddings\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# from langchain import hub\n",
    "# from langchain.agents import create_openai_functions_agent\n",
    "# from langchain.agents import AgentExecutor\n",
    "# from langchain.pydantic_v1 import BaseModel, Field\n",
    "# from langchain_core.messages import BaseMessage\n",
    "# from langserve import add_routes\n",
    "\n",
    "# # 1. Load Retriever\n",
    "# loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "# docs = loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter()\n",
    "# documents = text_splitter.split_documents(docs)\n",
    "# # embeddings = OpenAIEmbeddings()\n",
    "# embeddings = CohereEmbeddings()\n",
    "# vector = FAISS.from_documents(documents, embeddings)\n",
    "# retriever = vector.as_retriever()\n",
    "\n",
    "# # 2. Create Tools\n",
    "# retriever_tool = create_retriever_tool(\n",
    "#     retriever,\n",
    "#     \"langsmith_search\",\n",
    "#     \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    "# )\n",
    "# search = TavilySearchResults()\n",
    "# tools = [retriever_tool, search]\n",
    "\n",
    "\n",
    "# # 3. Create Agent\n",
    "# prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# # 4. App definition\n",
    "# app = FastAPI(\n",
    "#     title=\"LangChain Server\",\n",
    "#     version=\"1.0\",\n",
    "#     description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    "# )\n",
    "\n",
    "# # 5. Adding chain route\n",
    "\n",
    "# # We need to add these input/output schemas because the current AgentExecutor\n",
    "# # is lacking in schemas.\n",
    "\n",
    "\n",
    "# class Input(BaseModel):\n",
    "#     input: str\n",
    "#     chat_history: List[BaseMessage] = Field(\n",
    "#         ...,\n",
    "#         extra={\"widget\": {\"type\": \"chat\", \"input\": \"location\"}},\n",
    "#     )\n",
    "\n",
    "\n",
    "# class Output(BaseModel):\n",
    "#     output: str\n",
    "\n",
    "\n",
    "# add_routes(\n",
    "#     app,\n",
    "#     agent_executor.with_types(input_type=Input, output_type=Output),\n",
    "#     path=\"/agent\",\n",
    "# )\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import uvicorn\n",
    "\n",
    "#     uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playground\n",
    "- http://localhost:8000/agent/playground/ 접속\n",
    "- Input : LangSmith 가 테스트를 어떻게 도와줄 수 있나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'LangSmith는 다양한 주제에 대한 정보를 제공하고, 검색을 통해 필요한 정보를 찾아주는 도구입니다. 또한 LangSmith를 통해 특정 주제에 대한 질문에 대한 답변을 얻을 수도 있습니다. LangSmith를 활용하여 원하는 정보를 빠르게 찾아보세요!'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/agent/\")\n",
    "remote_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"LangSmith 가 테스트를 어떻게 도와줄 수 있나요?\",\n",
    "        \"chat_history\": [],  # Providing an empty list as this is the first call\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
