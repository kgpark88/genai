{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMUrWfETCvXg"
   },
   "source": [
    "# LangChain Quickstart\n",
    "- Code ì¶œì²˜ : https://python.langchain.com/docs/get_started/quickstart \n",
    "- ìˆ˜ì •ì‚¬í•­ : ì„¤ëª…ê³¼ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ í•œê¸€ë¡œ ë³€ê²½ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# langchain-community 0.0.19 ì„¤ì¹˜ ì´ìœ  - ModuleNotFoundError: No module named 'pwd' í•´ê²° \n",
    "# %pip install -qU langchain langchain-community==0.0.19\n",
    "%pip install -qU langchain langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai langchain-anthropic cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI_API_KEY API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ \n",
    "- API Key :  https://platform.openai.com/api-keys\n",
    "- Command Prompt/Termial ì—ì„œ ì•„ë˜ ëª…ë ì–´ ì‹¤í–‰ : `Ctrl + ` \n",
    "    - Windows : setx OPENAI_API_KEY=\"...\"\n",
    "    - macOS, Linux : export OPENAI_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTHROPIC API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ \n",
    "- API Key :  https://console.anthropic.com/settings/keys\n",
    "- Command Prompt/Termial ì—ì„œ ì•„ë˜ ëª…ë ì–´ ì‹¤í–‰ : `Ctrl + ` \n",
    "    - Windows : setx ANTHROPIC_API_KEY=\"...\"\n",
    "    - macOS, Linux : export ANTHROPIC_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COHERE_API_KEY API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ \n",
    "- API Key :  https://dashboard.cohere.com/api-keys\n",
    "- Command Prompt/Termial ì—ì„œ ì•„ë˜ ëª…ë ì–´ ì‹¤í–‰ : `Ctrl + ` \n",
    "    - Windows : setx COHERE_API_KEY=\"...\"\n",
    "    - macOS, Linux : export COHERE_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"COHERE_API_KEY\"] = \"your COHERE_API_KEY API key if not set as env var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatCohere\n",
    "\n",
    "# llm = ChatCohere(cohere_api_key=\"...\")\n",
    "llm = ChatCohere()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì›í•˜ëŠ” LLMì„ ì„¤ì¹˜í•˜ê³  ì´ˆê¸°í™”í–ˆìœ¼ë©´ ì´ì œ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!   \n",
    "í•™ìŠµ ë°ì´í„°ì— ì—†ë˜ ê²ƒì´ë¯€ë¡œ ê·¸ë‹¤ì§€ ì¢‹ì€ responseê°€ ë‚˜ì˜¤ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangsmithëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n1. ìë™í™” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì •ì˜í•˜ê³ , í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ìë™í™”í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ì¦ê°€ì‹œí‚¤ê³  í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì˜ ì¼ê´€ì„±ì„ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: LangsmithëŠ” í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ì…ë ¥ ê°’ê³¼ scenarioë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ íš¨í•œ ê°’, ë¬´íš¨í•œ ê°’, ê²½ê³„ ê°’ ë“±ì„ í¬í•¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ í…ŒìŠ¤íŠ¸ì˜ ë²”ìœ„ì™€ ê¹Šì´ë¥¼ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n3. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì„¤ê³„: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì„¤ê³„í•˜ê³  êµ¬ì¡°í™”í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì •ì˜í•˜ê³ , í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê°„ ì¤‘ë³µì„±ì„ ì‹ë³„í•˜ë©°, í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì¡°ì§í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n4. í…ŒìŠ¤íŠ¸ ê³„íš ë° ê´€ë¦¬: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ê³„íšì˜ ìƒì„±, í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìš°ì„ ìˆœìœ„ ì„¤ì •, í…ŒìŠ¤íŠ¸ ì¼ì • ê´€ë¦¬ ë“± í…ŒìŠ¤íŠ¸ ê³„íšì„ ì„¸ìš°ê³  ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n5. ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì§€ì›: LangsmithëŠ” ìˆ˜ë™ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ì§€ì›í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰, í…ŒìŠ¤íŠ¸ ë¡œê·¸ ê¸°ë¡, í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë¶„ì„ ë“±ì„ ìë™í™”í•˜ì—¬ ìˆ˜ë™ í…ŒìŠ¤íŠ¸ì˜ íš¨ìœ¨ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n6. ì§€ì†ì  í†µí•© ë° ì§€ì†ì  ë°°í¬(CI/CD)ì™€ í†µí•©: LangsmithëŠ” CI/CD í”„ë¡œì„¸ìŠ¤ì™€ í†µí•©ë˜ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ê³ , í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ë©°, í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œ ì•Œë¦¼ì„ ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n7. í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ê²°ê³¼ì™€ ì»¤ë²„ë¦¬ì§€ë¥¼ ìš”ì•½í•˜ê³  ì‹œê°í™”ëœ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë‹´ë‹¹ìì™€ ì´í•´ê´€ê³„ìë“¤ì´ í…ŒìŠ¤íŠ¸ ì§„í–‰ ìƒí™©ê³¼ ì‘ìš© í”„ë¡œê·¸ë¨ì˜ í’ˆì§ˆì— ëŒ€í•œ í†µì°°ë ¥ì„ ì–»ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. \\n\\nì „ì²´ì ìœ¼ë¡œ, LangsmithëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ ìë™í™”, í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬, í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì„¤ê³„ ë° í…ŒìŠ¤íŠ¸ ê³¼ì •ì˜ íš¨ìœ¨ì„± í–¥ìƒì„ í†µí•´ í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ íš¨ìœ¨ì„±ê³¼ íš¨ê³¼ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.', response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'token_count': {'prompt_tokens': 79, 'response_tokens': 458, 'total_tokens': 537, 'billed_tokens': 471}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"langsmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt template : ì‚¬ìš©ì ì…ë ¥ì„ LLMì— ë” ë‚˜ì€ ì…ë ¥ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x0nefArFCvXi"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì„¸ê³„ì ì¸ ìˆ˜ì¤€ì˜ ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ìì…ë‹ˆë‹¤.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### llmê³¼ promptë¥¼ ê°„ë‹¨í•œ LLM chainìœ¼ë¡œ ê²°í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangsmithëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì— ì—¬ëŸ¬ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± : LangsmithëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ì™€ ìŠ¤íƒ€ì¼ë¡œ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ì–¸ì–´ë³„ í…ŒìŠ¤íŠ¸ ë˜ëŠ” ë‹¤ì–¸ì–´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ìƒì„±ì— ìœ ìš©í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í…ŒìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ê³ í’ˆì§ˆë¡œ ê°€ìƒ ëŒ€í™” ìƒëŒ€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n2. ìì—°ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ : LangsmithëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP) ëª¨ë¸ ë° ì•Œê³ ë¦¬ì¦˜ì˜ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¨ì–´ì˜ ì˜ë¯¸ë‚˜ ë¬¸ì¥ì˜ ê³ ì¥ ê²€ì¶œê³¼ ê°™ì€ ì–¸ì–´ì  ì˜¤ë¥˜ ê²€ì¶œ, ê°ì • ë¶„ì„ ë˜ëŠ” ë¬¸ì¥ ë¶„ë¥˜ì™€ ê°™ì€ ê³¼ì œì— ëŒ€í•œ ground truth ë°ì´í„°ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n3. ë²ˆì—­ í…ŒìŠ¤íŠ¸ : LangsmithëŠ” ë‹¤ë¥¸ ì–¸ì–´ä¹‹é—´çš„ ë²ˆì—­ì˜ ì •í™•ì„±ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ì™€ ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¥¼ ë¹„êµí•˜ì—¬ ì˜¤ë¥˜ë‚˜ ë¶ˆì¼ì¹˜ë¥¼ ê°•ì¡° í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n4. ì‚¬ìš©ì„± í…ŒìŠ¤íŠ¸ : LangsmithëŠ” ì‚¬ìš©ì ê²½í—˜ ë° ì‚¬ìš©ì„± í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì‚¬ìš©ìì˜ ìƒí˜¸ ì‘ìš©ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ë©”ë‰´ì˜ ì´í•´ ê°€ëŠ¥ì„± ë˜ëŠ” ì ‘ê·¼ì„± ë¬¸ì œë¥¼ ì‹ë³„í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n5. ìë™í™”ëœ í…ŒìŠ¤íŠ¸ : LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‹¤í–‰í•˜ê³  í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìë™í™” ìŠ¤í¬ë¦½íŠ¸ì˜ ì‘ì„±ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–¸ì–´ì— ëŒ€í•œ ì§€ì‹ì„ í™œìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³ , í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ íŠ¹ì •í•œ ì–¸ì–´ì  íŒ¨í„´ì„ ìƒì„±í•˜ê³ , í…ŒìŠ¤íŠ¸ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n6. ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì§€ì› : LangsmithëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ ìˆ˜ë™ ìš”ì†Œë“¤ì„ ì§€ì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ë¬¸ì„œí™”í•˜ê³ , í…ŒìŠ¤íŠ¸ ê³„íšê³¼ ì§€ì¹¨ì„ ì‘ì„±í•˜ë©°, í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì„ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\nì „ë°˜ì ìœ¼ë¡œ, LangsmithëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±, ì–¸ì–´ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì§€ì›, í…ŒìŠ¤íŠ¸ íš¨ìœ¨ì„± í–¥ìƒ ë° í…ŒìŠ¤íŠ¸ ë¬¸ì„œí™” ë“± í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ìœ ìš©í•œ ë„êµ¬ì…ë‹ˆë‹¤.', response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'token_count': {'prompt_tokens': 94, 'response_tokens': 456, 'total_tokens': 550, 'billed_tokens': 481}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"langsmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### ì±„íŒ… Messageë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” ê°„ë‹¨í•œ OutputParserë¥¼ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangsmithëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì— ì—¬ëŸ¬ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë©ë‹ˆë‹¤. \\n\\n1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: LangsmithëŠ” ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ê°œì„ í•˜ê³  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ í™•ì¥í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, LangsmithëŠ” ë‹¤ë¥¸ ê¸¸ì´ì˜ ë¬¸ì¥ì´ë‚˜ ëœë¤í•œ ë‹¨ì–´ë¡œ ëœ ê°€ìƒ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™í™”: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìë™í™”í•˜ì—¬ ìˆ˜ë™ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ì†Œí™”í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì—°ì–´ ì²˜ë¦¬ ë˜ëŠ” ì–¸ì–´ ëª¨ë¸ë§ê³¼ ê°™ì€ ì–¸ì–´ ê´€ë ¨ í…ŒìŠ¤íŠ¸ì˜ ê²½ìš°, LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì •ì˜í•˜ê³  ì‹¤í–‰í•˜ë©° ê²°ê³¼ì™€ ê¸°ëŒ€ê°’ì„ ë¹„êµí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n3. ì–¸ì–´ í…ŒìŠ¤íŠ¸ì˜ íš¨ìœ¨ì„± í–¥ìƒ: LangsmithëŠ” ì—¬ëŸ¬ ì–¸ì–´ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‹ ì†í•˜ê²Œ ì‹¤í–‰í•˜ì—¬ ë‹¤ì–¸ì–´ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ì˜ íš¨ìœ¨ì„±ì„ ë†’ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì–¸ì–´ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ìë™í™”í•˜ì—¬ ì‹œê°„ê³¼ ë…¸ë ¥ì„ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n4. ì–¸ì–´ì  ì˜¤ë¥˜ ê²€ì¶œ: LangsmithëŠ” ì–¸ì–´ì  ì˜¤ë¥˜ë‚˜ ì´ìƒ í˜„ìƒì„ ê²€ì¶œí•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë„êµ¬ë“¤ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë¬¸ë²• ì²´í¬ í”„ë¡œê·¸ë¨ì´ë‚˜ ë°œìŒ ê²€ì¦ ë„êµ¬ì™€ ê°™ì€ ë„êµ¬ë“¤ì€ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ ì¼ë¶€ë¡œ í†µí•©í•˜ì—¬ ì–¸ì–´ì  ì¼ê´€ì„±ì„ ê²€ì¦í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n5. ì¸ê°„ í‰ê°€ì™€ì˜ ì¡°í•©: LangsmithëŠ” ì¸ê°„ í‰ê°€ìì™€ ì¡°í•©í•˜ì—¬ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ ì •í™•ë„ì™€ ìœ íš¨ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–¸ì–´ ëª¨ë¸ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ë° ì¸ê°„ í‰ê°€ìë¥¼ ìœ„í•œ ê°€ì´ë“œë¼ì¸ê³¼ ë„êµ¬ë¥¼ ì œê³µí•˜ì—¬ ê·¸ë“¤ì˜ í‰ê°€ë¥¼ ë” ì¼ê´€ë˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n6. í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ê²°ê³¼ì™€ ë©”íŠ¸ë¦­ìŠ¤ë¥¼ ìš”ì•½í•˜ê³  ì‹œê°í™”í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ íˆ¬ëª…ì„±ê³¼ ê°€ì‹œì„±ì„ ê°œì„ í•˜ë©°, ì´í•´ê´€ê³„ìì—ê²Œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì˜ ë¶„ì„ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤. \\n\\nì „ì²´ì ìœ¼ë¡œ, LangsmithëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ìƒì„±, í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™í™”, í…ŒìŠ¤íŠ¸ íš¨ìœ¨ì„± í–¥ìƒ, ì–¸ì–´ì  ë¬¸ì œ ê²€ì¶œ, ì¸ê°„ í‰ê°€ì™€ì˜ í†µí•© ë° í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±ì— ëŒ€í•œ ì§€ì›ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì— ê·€ì¤‘í•œ ë„êµ¬ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì—°ì–´ ì²˜ë¦¬, ì–¸ì–´ ëª¨ë¸ë§ ë˜ëŠ” ì–¸ì–´ ê´€ë ¨ ì†Œí”„íŠ¸ì›¨ì–´ í…ŒìŠ¤íŠ¸ì™€ ê°™ì€ ì–¸ì–´ í…ŒìŠ¤íŠ¸ì˜ í’ˆì§ˆê³¼ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"input\": \"langsmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval Chain\n",
    "- ì§ˆë¬¸ì— ì œëŒ€ë¡œ ë‹µí•˜ë ¤ë©´ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. Retrievalì„ í†µí•´ ì´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "- Retrieval(ê²€ìƒ‰)ì€ LLMì— ì§ì ‘ ì „ë‹¬í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ë§ì€ ë°ì´í„°ê°€ ìˆì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤. \n",
    "- ê´€ë ¨ ë°ì´í„°ì—ì„œ Retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¶€ë¶„ë§Œ ê°€ì ¸ì™€ì„œ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬í•©ë‹ˆë‹¤. \n",
    "- ì•„ë˜ ì½”ë“œëŠ” ë²¡í„°ìŠ¤í† ì–´ì— ë°ì´í„°ë¥¼ ì €ì¥í•œ í›„, ì´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoupì„ ì„¤ì¹˜í•˜ê³ , WebBaseLoaderë¡œ ì›¹í˜ì´ì§€ ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„°ë¥¼ ì„ë² ë”©ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ë²¡í„°ìŠ¤í† ì–´ë¡œ ìƒ‰ì¸í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# FAISS(Fast Approximate Nearest Neighbor Search) ì„¤ì¹˜\n",
    "%pip install -qU faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Chain ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"ì œê³µëœ contextì—ë§Œ ê·¼ê±°í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ì—¬ ì´í•´í•˜ê¸° ì‰½ê³  í•´ì„í•˜ê¸° ì‰¬ìš´ ë°©ì‹ìœ¼ë¡œ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë” íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì´í•´í•  ìˆ˜ ìˆìœ¼ë©°, í…ŒìŠ¤íŠ¸ ê²°ê³¼ì˜ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ë” ë¶„ëª…í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê·¸ë˜í”„ì™€ ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ Coverageë¥¼ í‘œì‹œí•˜ê±°ë‚˜, ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ í…ŒìŠ¤íŠ¸ì˜ íš¨ìœ¨ì„±ê³¼ íš¨ê³¼ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"LangSmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "    \"context\": [Document(page_content=\"LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmithëŠ” ê°œë°œìê°€ ë””ë²„ê¹…í•˜ê³ , í…ŒìŠ¤íŠ¸í•˜ê³ , í‰ê°€í•˜ê³ , ì‚¬ìŠ¬ê³¼ ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¥¼ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆëŠ” í”Œë«í¼ìœ¼ë¡œ, LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ìˆ˜ëª… ì£¼ê¸° ì „ì²´ì—ì„œ ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'í‰ê°€' ì„¹ì…˜ì— ì„¤ëª…ëœ ë°”ì™€ ê°™ì´, LangSmithëŠ” í…ŒìŠ¤íŠ¸ ë° í‰ê°€ì— ëŒ€í•œ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œë¥¼ ì œê³µí•˜ì—¬ ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°œë°œìëŠ” LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ìš© í”„ë¡œê·¸ë¨ì„ í…ŒìŠ¤íŠ¸í•˜ê³ , ë‹¤ì–‘í•œ ê²½ìš°ì˜ ìˆ˜ë¥¼ ì‹¤í—˜í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë˜í•œ LangSmithì˜ 'ì¶”ì 'ê¸°ëŠ¥ì€ ê°œë°œìê°€ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì¶”ì ì„ ì„¤ì •í•˜ì—¬ ë¬¸ì œ í•´ê²°ì— ë„ì›€ì´ ë˜ëŠ” ê·€ì¤‘í•œ í†µì°°ë ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"LangSmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conversation Retrieval Chain\n",
    "- LLM ì£¼ìš” ì• í”Œë¦¬ì¼€ì´ì…˜ì¸ ì±„íŒ…ë´‡ êµ¬í˜„ì‹œì—ëŠ” ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- create_retrieval_chain í•¨ìˆ˜ ì‚¬ìš©ì‹œ 2ê°€ì§€ë¥¼ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "    - ê²€ìƒ‰ ë°©ë²•ì€ ì´ì œ ê°€ì¥ ìµœê·¼ì˜ ì…ë ¥ë§Œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.  \n",
    "    - ìµœì¢… LLM ì²´ì¸ë„ ë§ˆì°¬ê°€ì§€ë¡œ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Retrieval  \n",
    "- ê²€ìƒ‰ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ìƒˆ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.  \n",
    "- ì´ ì²´ì¸ì€ ê°€ì¥ ìµœê·¼ì˜ ì…ë ¥(input)ê³¼ ëŒ€í™” ê¸°ë¡(chat_history)ì„ ë°›ì•„ LLMì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í›„ì† ì§ˆë¬¸ì„ í•˜ì—¬ ì´ë¥¼ í…ŒìŠ¤íŠ¸í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'Introduction', 'language': 'en'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"),\n",
    "    AIMessage(content=\"ì˜ˆ!\"),\n",
    "]\n",
    "\n",
    "retriever_chain.invoke({\"chat_history\": chat_history, \"input\": \"ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì´ë ‡ê²Œ í•˜ë©´ LangSmithì—ì„œ í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ ë¬¸ì„œê°€ ë°˜í™˜ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "- ì´ëŠ” LLMì´ ì±„íŒ… íˆìŠ¤í† ë¦¬ì™€ í›„ì† ì§ˆë¬¸ì„ ê²°í•©í•˜ì—¬ ìƒˆë¡œìš´ ì¿¼ë¦¬ë¥¼ ìƒì„±í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "- ì´ì œ ìƒˆë¡œìš´ retrieverê°€ ìƒê²¼ìœ¼ë‹ˆ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì—¼ë‘ì— ë‘ê³  ëŒ€í™”ë¥¼ ê³„ì†í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì²´ì¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End-to-endë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?'),\n",
       "  AIMessage(content='ì˜ˆ!')],\n",
       " 'input': 'ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.',\n",
       " 'context': [Document(page_content=\"LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'Introduction', 'language': 'en'})],\n",
       " 'answer': 'LangSmithëŠ” LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ê°œë°œ ë° í…ŒìŠ¤íŠ¸ì— ë„ì›€ì´ ë˜ëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ í…ŒìŠ¤íŠ¸ë¥¼ ë•ëŠ” ëª‡ ê°€ì§€ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n1. ë””ë²„ê¹…: LangSmithì˜ ì¶”ì  ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì…ì¶œë„ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ì—¬ ì˜¤ë¥˜ë‚˜ ì´ìƒê°’ì„ ì°¾ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ê°œë°œìëŠ” ì´ ê¸°ëŠ¥ì„ í†µí•´ ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì˜¤ë¥˜ë‚˜ ë¬¸ì œë¥¼ ì‹ ì†í•˜ê²Œ ì°¾ê³  ë””ë²„ê¹…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n2. í‰ê°€: LangSmithëŠ” í‰ê°€ ê¸°ëŠ¥ë„ ì œê³µí•˜ì—¬ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì„±ëŠ¥ì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°œë°œìëŠ” ì´ ê¸°ëŠ¥ì„ í†µí•´ ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì •í™•ë„, ì†ë„ì™€ ê°™ì€ ì„±ëŠ¥ ì§€í‘œë¥¼ ì¸¡ì •í•˜ê³ , ë‹¤ë¥¸ ì‘ìš© í”„ë¡œê·¸ë¨ê³¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n3. ëª¨ë‹ˆí„°ë§: LangSmithì˜ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì‹¤ì‹œê°„ ì„±ëŠ¥ê³¼ ê±´ê°• ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì´ìƒ í˜„ìƒì„ ê°ì§€í•˜ê³  ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‘ìš© í”„ë¡œê·¸ë¨ì´ ì˜ˆìƒëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ë•Œ ê²½ê³ ë¥¼ ë°›ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n4. í”„ë¡¬í”„íŠ¸ í—ˆë¸Œ: LangSmithì—ëŠ” í”„ë¡¬í”„íŠ¸ í—ˆë¸Œë¼ëŠ” ê¸°ëŠ¥ì´ ë‚´ì¥ë˜ì–´ ìˆì–´ ê°œë°œìê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ê´€ë¦¬í•˜ê³  ì‚¬ìš©ì ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°œë°œìëŠ” ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•˜ì—¬ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì¶œìë¥¼ ë‹¤ì–‘í•˜ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\nì´ ì™¸ì—ë„ LangSmithëŠ” LangChainì´ë¼ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ LLM í”„ë ˆì„ì›Œí¬ì™€ í†µí•©ë˜ì–´ ìˆì–´, ê°œë°œìê°€ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì„ êµ¬ì¶•í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë‹¤ì–‘í•œ ë„êµ¬ì™€ ìì›ì„ ì œê³µí•©ë‹ˆë‹¤. LangSmith ë¬¸ì„œì˜ ê°€ì´ë“œë¥¼ ë”°ë¼ ê³„ì •ì„ ë§Œë“¤ê³  API í‚¤ë¥¼ ì–»ìœ¼ë©´ LangSmithì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"),\n",
    "    AIMessage(content=\"ì˜ˆ!\"),\n",
    "]\n",
    "\n",
    "retrieval_chain.invoke({\"chat_history\": chat_history, \"input\": \"ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent - OpenAI API Key í•„ìš”\n",
    "- AgentëŠ” LLMì´ ìˆ˜í–‰í•  ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "- Agentë¥¼ ë§Œë“¤ ë•Œ Agentê°€ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” ë„êµ¬(Tool)ì„ ì •í•©ë‹ˆë‹¤.\n",
    "- ì´ ì˜ˆì—ì„œëŠ” ì—ì´ì „íŠ¸ì—ê²Œ 2ê°œì˜ Toolì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ ê¶Œí•œì„ ë¶€ì—¬í•˜ê² ìŠµë‹ˆë‹¤:\n",
    "    1. ë°©ê¸ˆ ë§Œë“  Retriever : LangSmithì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€\n",
    "    2. ê²€ìƒ‰ ë„êµ¬(Search tool) : ìµœì‹  ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸ì— ë‹µë³€  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieverë¥¼ ìœ„í•œ íˆ´ì„ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tavily(Search ì—”ì§„) API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ \n",
    "- API Key - https://app.tavily.com/  \n",
    "- Command Prompt/Termial ì—ì„œ ì•„ë˜ ëª…ë ì–´ ì‹¤í–‰ : `Ctrl + ` \n",
    "    - Windows : setx  TAVILY_API_KEY=\"...\"\n",
    "    - macOS, Linux : export TAVILY_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"<your Tavily API key if not set as env var>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### ë¯¸ë¦¬ ì •ì˜ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ langchain hub ì„¤ì¹˜\n",
    " https://smith.langchain.com/hub/  \n",
    " https://smith.langchain.com/hub/hwchase17/openai-functions-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__b65e9f75a6b74a72ad48df022821e1ce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agentë¥¼ í˜¸ì¶œí•˜ê³  Agentì˜ ì‘ë‹µì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'How can LangSmith help with tests?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Startâ€‹Tracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Stepsâ€‹Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmithëŠ” í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì£¼ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ LLM í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì²´ì¸ ë° ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¥¼ ë””ë²„ê¹…, í…ŒìŠ¤íŠ¸, í‰ê°€ ë° ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangSmithëŠ” LangChainê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ìˆìœ¼ë©°, LangChainì€ LLMê³¼ ê´€ë ¨ëœ ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ í‰ê°€í•˜ë©°, LangSmithì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LangSmithì˜ ì‚¬ìš©ì ê°€ì´ë“œì™€ ê´€ë ¨ ì„¹ì…˜ì„ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmithê°€ í…ŒìŠ¤íŠ¸ì— ì–´ë–¤ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?',\n",
       " 'output': 'LangSmithëŠ” í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì£¼ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ LLM í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì²´ì¸ ë° ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¥¼ ë””ë²„ê¹…, í…ŒìŠ¤íŠ¸, í‰ê°€ ë° ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangSmithëŠ” LangChainê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ìˆìœ¼ë©°, LangChainì€ LLMê³¼ ê´€ë ¨ëœ ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ í‰ê°€í•˜ë©°, LangSmithì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LangSmithì˜ ì‚¬ìš©ì ê°€ì´ë“œì™€ ê´€ë ¨ ì„¹ì…˜ì„ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"LangSmithê°€ í…ŒìŠ¤íŠ¸ì— ì–´ë–¤ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081', 'content': 'ì„œìš¸ì‹œëŠ” ì˜¤ëŠ˜ 2ì›” 19ì¼ ì €ë…ì— ë‡Œìš°ê°€ ë‚´ë¦¬ê³  ìµœì € ì˜¨ë„ëŠ” 32Â°Fì…ë‹ˆë‹¤. ë°¤ì—ëŠ” íë¦¬ê³  ë°”ëŒì´ ê°•í•˜ë©°, ë°¤ì‚¬ì´ í•´ì™€ ë‹¬ì€ 10ì‹œê°„ 57ë¶„'}, {'url': 'https://weather.com/ko-KR/weather/today/l/82e46175f97c224acf6b95afc4934fbae0e4ba123adcee8a52b7be97c303467b', 'content': 'The Weather Channel ë° Weather.comì´ ì œê³µí•˜ëŠ” ì˜¤ëŠ˜ê³¼ ì˜¤ëŠ˜ ë°¤ ì„œìš¸íŠ¹ë³„ì‹œ ì¼ê¸°ì˜ˆë³´, ë‚ ì”¨ ìƒíƒœ ë° ë„í”ŒëŸ¬ ë ˆì´ë”'}, {'url': 'https://www.weather.go.kr/weather/home/index.jsp', 'content': 'ê¸°ìƒì²­ ë‚ ì”¨ëˆ„ë¦¬ - êµ­ê°€ê¸°ìƒì¢…í•©ì •ë³´ ... ê²½ìƒë‚¨ë„(ì–‘ì‚°, ì°½ì›, ê¹€í•´, ë°€ì–‘, ì˜ë ¹, ì°½ë…•, ì‚°ì²­, í•¨ì–‘, í•©ì²œ, ì‚¬ì²œ, ê±°ì œ, ë‚¨í•´), ì„œìš¸(ë™ë‚¨ê¶Œ, ë™ë¶ê¶Œ), ëŒ€êµ¬(êµ°ìœ„ ì œì™¸), ë¶€ì‚°, ìš¸ì‚° ... ì•„ì¹¨ ê¸°ì˜¨ì€ -4~2ë„ë¡œ ì˜¤ëŠ˜(20ì¼, -3.5~4.8ë„)ë³´ë‹¤ 2~5ë„ê°€ëŸ‰ ë‚®ê² ê³ , íŠ¹íˆ ë‚´ë¥™ì„ ...'}, {'url': 'https://www.accuweather.com/ko/kr/seoul/226081/hourly-weather-forecast/226081', 'content': 'ì„œìš¸ì‹œì—ì„œ ì˜¤ëŠ˜ ì˜¤ì „ 7ì‹œë¶€í„° ì˜¤í›„ 11ì‹œê¹Œì§€ëŠ” ë¹„ê°€ ë‚´ë¦¬ê³  ìŠµë„ê°€ ë†’ê³  ëŒ€ê¸°ì§ˆì´ ë‚˜ì¨ì…ë‹ˆë‹¤. ì˜¤í›„ 11ì‹œë¶€í„°ëŠ” ë¹„ê°€ ë©ˆê³  êµ¬ë¦„ì´ ë®ì´ê³  ìµœê³  ê¸°ì˜¨ì€ 54ë„, ìµœì € ê¸°ì˜¨ì€ 43ë„ì…ë‹ˆë‹¤.'}, {'url': 'https://www.weather.go.kr/w/index.do', 'content': 'ê¸°ìƒì²­ ë‚ ì”¨ëˆ„ë¦¬. ë°€ë¬¼Â·ì°ë¬¼ ì •ë³´ í•´ì™€ ë‹¬ì´ ëœ¨ê³ ì§€ëŠ” ì‹œê°„ ê¸°í›„ì •ë³´í¬í„¸ ê¸°ìƒìë£Œ ê°œë°©í¬í„¸ ê¸°ìƒê¸°í›„ ë¹…ë°ì´í„° ëŒ€ê¸°ì§ˆ ì˜ˆÂ·ê²½ë³´ ë‚ ì”¨í•´ì„¤ (ìœ íŠœë¸Œ) ê¸°ìƒì²­ í–‰ì •ëˆ„ë¦¬ì§‘ ì‚°ì•…ë‚ ì”¨ í•œê°•í™ìˆ˜í†µì œì†Œ í•´ì–‘ê¸°ìƒ ì •ë³´í¬í„¸ í•­ê³µê¸°ìƒì²­. ì•„ì´ì½˜, ì„¤ëª…ìœ¼ë¡œ ë‚ ì”¨ ì•„ì´ì½˜ì„ ...'}]\u001b[0m\u001b[32;1m\u001b[1;3mì„œìš¸ì˜ ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì €ë…ì— ë‡Œìš°ê°€ ë‚´ë¦¬ê³  ìµœì € ì˜¨ë„ëŠ” 32Â°Fì…ë‹ˆë‹¤. ë°¤ì—ëŠ” íë¦¬ê³  ë°”ëŒì´ ê°•í•˜ë©°, ë°¤ì‚¬ì´ í•´ì™€ ë‹¬ì€ 10ì‹œê°„ 57ë¶„ ë™ì•ˆ ë³´ì…ë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ë¥¼ ì›í•˜ì‹œë©´ [ì—¬ê¸°](https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081)ë¥¼ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ”?',\n",
       " 'output': 'ì„œìš¸ì˜ ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì €ë…ì— ë‡Œìš°ê°€ ë‚´ë¦¬ê³  ìµœì € ì˜¨ë„ëŠ” 32Â°Fì…ë‹ˆë‹¤. ë°¤ì—ëŠ” íë¦¬ê³  ë°”ëŒì´ ê°•í•˜ë©°, ë°¤ì‚¬ì´ í•´ì™€ ë‹¬ì€ 10ì‹œê°„ 57ë¶„ ë™ì•ˆ ë³´ì…ë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ë¥¼ ì›í•˜ì‹œë©´ [ì—¬ê¸°](https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081)ë¥¼ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'How can LangSmith help with LLM application testing?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Startâ€‹Tracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Stepsâ€‹Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmithëŠ” í”„ë¡œë•ì…˜ê¸‰ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ ì–´ë–¤ LLM í”„ë ˆì„ì›Œí¬ë¡œ êµ¬ì¶•ëœ ì²´ì¸ ë° ì§€ëŠ¥ì  ì—ì´ì „íŠ¸ë¥¼ ë””ë²„ê¹…, í…ŒìŠ¤íŠ¸, í‰ê°€ ë° ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangSmithëŠ” LangChainê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ë©°, LangChainì€ LLMìœ¼ë¡œ êµ¬ì¶•í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LangSmithì˜ ì‚¬ìš©ì ê°€ì´ë“œì™€ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™•ì¸í•´ë³´ì„¸ìš”.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?'),\n",
       "  AIMessage(content='ì˜ˆ!')],\n",
       " 'input': 'ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.',\n",
       " 'output': 'LangSmithëŠ” í”„ë¡œë•ì…˜ê¸‰ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ ì–´ë–¤ LLM í”„ë ˆì„ì›Œí¬ë¡œ êµ¬ì¶•ëœ ì²´ì¸ ë° ì§€ëŠ¥ì  ì—ì´ì „íŠ¸ë¥¼ ë””ë²„ê¹…, í…ŒìŠ¤íŠ¸, í‰ê°€ ë° ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangSmithëŠ” LangChainê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ë©°, LangChainì€ LLMìœ¼ë¡œ êµ¬ì¶•í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LangSmithì˜ ì‚¬ìš©ì ê°€ì´ë“œì™€ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™•ì¸í•´ë³´ì„¸ìš”.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"),\n",
    "    AIMessage(content=\"ì˜ˆ!\"),\n",
    "]\n",
    "agent_executor.invoke({\"chat_history\": chat_history, \"input\": \"ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Serving with LangServe\n",
    "#### langserve, fastapië¥¼ ì„¤ì¹˜í•˜ê³  ë¡œì»¬ì‹œìŠ¤í…œ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "#### `py311\\Scripts\\activate`  ë˜ëŠ” `source py311/bin/activate` \n",
    "#### `cd code`        \n",
    "#### `python server.py`    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langserve fastapi sse_starlette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë…¸íŠ¸ë¶ì—ì„œ ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš”.  \n",
    "#### server.py íŒŒì¼ì˜ ë‚´ìš©ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "from typing import List\n",
    "from fastapi import FastAPI\n",
    "from llama_index.embeddings.voyageai import VoyageEmbedding\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langserve import add_routes\n",
    "\n",
    "# 1. Load Retriever\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "voyage_api_key = os.environ.get(\n",
    "    \"VOYAGE_API_KEY\", \"pa-jdSGqKsXLMgpQf3zLEqWmZLKaONv7w_C5U-6mqMc8TU\"\n",
    ")\n",
    "embeddings = VoyageEmbedding(model_name=\"voyage-2\", voyage_api_key=voyage_api_key)\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# 2. Create Tools\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")\n",
    "search = TavilySearchResults()\n",
    "tools = [retriever_tool, search]\n",
    "\n",
    "\n",
    "# 3. Create Agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# 4. App definition\n",
    "app = FastAPI(\n",
    "    title=\"LangChain Server\",\n",
    "    version=\"1.0\",\n",
    "    description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "# 5. Adding chain route\n",
    "\n",
    "# We need to add these input/output schemas because the current AgentExecutor\n",
    "# is lacking in schemas.\n",
    "\n",
    "\n",
    "class Input(BaseModel):\n",
    "    input: str\n",
    "    chat_history: List[BaseMessage] = Field(\n",
    "        ...,\n",
    "        extra={\"widget\": {\"type\": \"chat\", \"input\": \"location\"}},\n",
    "    )\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    output: str\n",
    "\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    agent_executor.with_types(input_type=Input, output_type=Output),\n",
    "    path=\"/agent\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playground\n",
    "- http://localhost:8000/agent/playground/ ì ‘ì†\n",
    "- Input : LangSmith ê°€ í…ŒìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'LangSmithëŠ” ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ê²€ìƒ‰ì„ í†µí•´ í•„ìš”í•œ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ë˜í•œ LangSmithë¥¼ í†µí•´ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì–»ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. LangSmithë¥¼ í™œìš©í•˜ì—¬ ì›í•˜ëŠ” ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ì°¾ì•„ë³´ì„¸ìš”!'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/agent/\")\n",
    "remote_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"LangSmith ê°€ í…ŒìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "        \"chat_history\": [],  # Providing an empty list as this is the first call\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ìƒì„±í˜• AI í™œìš© ì‹¤ìŠµ  \n",
    "- 1. server.py ì½”ë“œ ì„¤ëª…   \n",
    "- 2. server.py ì½”ë“œ ë¦¬ë·°\n",
    "- 3. server.py ì½”ë“œ ë¦¬íŒ©í† ë§\n",
    "- 4. server.py ì£¼ì„ ì¶”ê°€"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
