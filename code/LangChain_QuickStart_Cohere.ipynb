{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMUrWfETCvXg"
   },
   "source": [
    "# LangChain Quickstart\n",
    "- Code ì¶œì²˜ : https://python.langchain.com/docs/get_started/quickstart \n",
    "- ìˆ˜ì •ì‚¬í•­ : ì„¤ëª…ê³¼ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ í•œê¸€ë¡œ ë³€ê²½ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ModuleNotFoundError: No module named 'pwd' ì—ëŸ¬ ë°œìƒì‹œì—ëŠ” langchain-community==0.0.19 ì„¤ì¹˜\n",
    "%pip install -qU langchain langchain-community langchain-openai langchain-anthropic cohere llama-index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI_API_KEY API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ \n",
    "- API Key :  https://platform.openai.com/api-keys\n",
    "- Command Prompt/Termial ì—ì„œ ì•„ë˜ ëª…ë ì–´ ì‹¤í–‰ : `Ctrl + ` \n",
    "    - Windows : setx OPENAI_API_KEY=\"...\"\n",
    "    - macOS, Linux : export OPENAI_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTHROPIC API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ \n",
    "- API Key :  https://console.anthropic.com/settings/keys\n",
    "- Command Prompt/Termial ì—ì„œ ì•„ë˜ ëª…ë ì–´ ì‹¤í–‰ : `Ctrl + ` \n",
    "    - Windows : setx ANTHROPIC_API_KEY=\"...\"\n",
    "    - macOS, Linux : export ANTHROPIC_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COHERE_API_KEY API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ \n",
    "- API Key :  https://dashboard.cohere.com/api-keys\n",
    "- Command Prompt/Termial ì—ì„œ ì•„ë˜ ëª…ë ì–´ ì‹¤í–‰ : `Ctrl + ` \n",
    "    - Windows : setx COHERE_API_KEY=\"...\"\n",
    "    - macOS, Linux : export COHERE_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"COHERE_API_KEY\"] = \"your COHERE_API_KEY API key if not set as env var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatCohere\n",
    "\n",
    "# llm = ChatCohere(cohere_api_key=\"...\")\n",
    "llm = ChatCohere()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì›í•˜ëŠ” LLMì„ ì„¤ì¹˜í•˜ê³  ì´ˆê¸°í™”í–ˆìœ¼ë©´ ì´ì œ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!   \n",
    "í•™ìŠµ ë°ì´í„°ì— ì—†ë˜ ê²ƒì´ë¯€ë¡œ ê·¸ë‹¤ì§€ ì¢‹ì€ responseê°€ ë‚˜ì˜¤ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangsmithëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n1. ìë™í™” : LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‹¤í–‰í•˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ëŠ” ë“± ë°˜ë³µì ì´ê³  ì§€ë£¨í•œ í…ŒìŠ¤íŠ¸ ì‘ì—…ì˜ ìë™í™”ë¥¼ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ íŒ€ì´ ë” íš¨ìœ¨ì ì´ê³  ì •í™•í•˜ê²Œ ì¼í•  ìˆ˜ ìˆê²Œ í•´ì£¼ë©°, ìˆ˜ë™ í…ŒìŠ¤íŠ¸ì— ì†Œìš”ë˜ëŠ” ì‹œê°„ì„ ì¤„ì—¬ ì¤ë‹ˆë‹¤. \\n\\n2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± : LangsmithëŠ” ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìœ„í•´ ë‹¤ì–‘í•œ ì…ë ¥ scenarioë¥¼ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ê°œì„ í•˜ê³  í…ŒìŠ¤íŠ¸ì˜ ì§ˆì„ ë†’ì—¬ì£¼ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. \\n\\n3. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì„¤ê³„ : LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì„¤ê³„í•˜ëŠ” ê³¼ì •ë„ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ íŒ€ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ë” íš¨ê³¼ì ìœ¼ë¡œ ì„¤ê³„í•˜ê³ , ê²°í•¨ì´ ìˆëŠ” ê²½ìš°ë‚˜ ì¼ë°˜ì ì¸ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ë” ì˜ ì»¤ë²„í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì¶”ì²œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n4. ë¬¸ì„œí™” : LangsmithëŠ” í…ŒìŠ¤íŠ¸ ê³„íš, í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë° í…ŒìŠ¤íŠ¸ ê²°ê³¼ì™€ ê°™ì€ í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë¬¸ì„œì˜ ìƒì„± ë° ì—…ë°ì´íŠ¸ë¥¼ ìë™í™”í•˜ì—¬ ë¬¸ì„œí™” í”„ë¡œì„¸ìŠ¤ë¥¼ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ íŒ€ì˜ ì—…ë¬´ íš¨ìœ¨ì„±ì„ ë†’ì—¬ì£¼ê³ , ë‹¤ë¥¸ íŒ€ì›ë“¤ê³¼ì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ê°œì„ í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. \\n\\n5. ì§€ì†ì ì¸ í†µí•© ë° ì§€ì†ì ì¸ ë°°í¬(CI/CD) : LangsmithëŠ” CI/CD í”„ë¡œì„¸ìŠ¤ì— í†µí•©ë˜ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ê³ , í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ë”°ë¼ ë°°í¬ë¥¼ ìŠ¹ì¸ ë˜ëŠ” ê±°ë¶€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ê°€ ì½”ë“œì˜ ë³€ê²½ì‚¬í•­ê³¼ í•¨ê»˜ ìì£¼ ì‹¤í–‰ë˜ë„ë¡ ë³´ì¥í•˜ì—¬ ì†Œí”„íŠ¸ì›¨ì–´ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. \\n\\n6. íšŒê³ ë¡ ë¶„ì„ : LangsmithëŠ” í…ŒìŠ¤íŠ¸ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ê³¼ ì´ìƒì¹˜ë¥¼ ì‹ë³„í•˜ê³ , í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë¬¸ì œì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, LangsmithëŠ” íŠ¹ì • í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì—ì„œ ì‹¤íŒ¨ì˜ ê²½í–¥ì„ ì‹ë³„í•˜ê±°ë‚˜, í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ë¬¸ì œì ì„ ì‹ë³„í•˜ì—¬ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\nì „ì²´ì ìœ¼ë¡œ, LangsmithëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ íš¨ìœ¨ì„±ê³¼ íš¨ê³¼ì„±ì„ ë†’ì—¬ì£¼ê³ , í…ŒìŠ¤íŠ¸ íŒ€ì˜ ìƒì‚°ì„±ì„ ë†’ì—¬ì£¼ëŠ” í…ŒìŠ¤íŠ¸ ìë™í™” ë° ì§€ì› ë„êµ¬ë¡œ í…ŒìŠ¤íŠ¸ì— í° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.', response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'token_count': {'prompt_tokens': 79, 'response_tokens': 489, 'total_tokens': 568, 'billed_tokens': 502}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"langsmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt template : ì‚¬ìš©ì ì…ë ¥ì„ LLMì— ë” ë‚˜ì€ ì…ë ¥ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x0nefArFCvXi"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì„¸ê³„ì ì¸ ìˆ˜ì¤€ì˜ ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ìì…ë‹ˆë‹¤.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### llmê³¼ promptë¥¼ ê°„ë‹¨í•œ LLM chainìœ¼ë¡œ ê²°í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangsmithëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì— ì—¬ëŸ¬ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n1. ìë™í™” í…ŒìŠ¤íŠ¸: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ëŠ” ìë™í™” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ì˜ ìƒì„±ì„ ì§€ì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê³  ì¸ê°„ ì˜¤ë¥˜ì˜ ê°€ëŠ¥ì„±ì„ ì¤„ì—¬ ì¤ë‹ˆë‹¤. \\n\\n2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë¬¸ì„œí™”í•˜ëŠ” ê²ƒì„ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ê°œì„ í•˜ê³  í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ ì¼ê´€ì„±ì„ ë³´ì¥í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ìƒì„±ê³¼ ê´€ë¦¬ë¥¼ ë•ê³ , í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ì…ë ¥ ê°’ê³¼ ê¸°ëŒ€ê°’ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ ë°ì´í„°ê°€ ë§ì€ í…ŒìŠ¤íŠ¸ scenarioì—ì„œ íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤. \\n\\n4. í…ŒìŠ¤íŠ¸ ê³„íš ë° ì¡°ì§: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ê³„íš ë° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìš°ì„  ìˆœìœ„ ê²°ì •ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ„í—˜ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ë©´ ê°€ì¥ ì¤‘ìš”í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ í•´ ì¤ë‹ˆë‹¤. \\n\\n5. ìˆ˜ë™ í…ŒìŠ¤íŠ¸ì˜ íš¨ìœ¨ì„± í–¥ìƒ: LangsmithëŠ” ìˆ˜ë™ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ í…ŒìŠ¤íŠ¸ ë‹´ë‹¹ìê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ë” ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë„ìš¸ ìˆ˜ ìˆëŠ” ë„êµ¬ë“¤ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n6. ì§€ì†ì ì¸ í†µí•© ë° ì§€ì†ì ì¸ ë°°í¬(CI/CD) í”„ë¡œì„¸ìŠ¤ì™€ì˜ í†µí•©: LangsmithëŠ” CI/CD í”„ë¡œì„¸ìŠ¤ì— í†µí•©ë˜ì–´ ìë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³ , í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ë”°ë¼ ë°°í¬ë¥¼ ìŠ¹ì¸ ë˜ëŠ” ê±°ë¶€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ ì†Œí”„íŠ¸ì›¨ì–´ì˜ í’ˆì§ˆì„ ë³´ì¥í•˜ê³  ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì›í™œí•˜ê²Œ í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n7. ê²°í•¨ ì¶”ì  ë° ê´€ë¦¬: LangsmithëŠ” ê²°í•¨ ì¶”ì  ì‹œìŠ¤í…œê³¼ í†µí•©ë˜ì–´ ê²°í•¨ì„ ì‹ ì†í•˜ê²Œ ë³´ê³ í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ ê²°í•¨ í•´ê²° í”„ë¡œì„¸ìŠ¤ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê³  í…ŒìŠ¤íŠ¸íŒ€ì´ ê²°í•¨ì˜ ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\nì „ì²´ì ìœ¼ë¡œ LangsmithëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì˜ íš¨ìœ¨ì„±ê³¼ íš¨ê³¼ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë„êµ¬ë“¤ê³¼ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.', response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'token_count': {'prompt_tokens': 94, 'response_tokens': 444, 'total_tokens': 538, 'billed_tokens': 469}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"langsmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### ì±„íŒ… Messageë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” ê°„ë‹¨í•œ OutputParserë¥¼ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangsmithëŠ” í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ì— ì—¬ëŸ¬ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n- í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: LangsmithëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë¬¸ë²•ì´ë‚˜ ì–¸ì–´ì  íŒ¨í„´ì´ ì˜¬ë°”ë¥¸ ë¬¸ì¥ì„ ìƒì„±í•˜ë„ë¡ ì„¤ê³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ìƒì„±ëœ ë°ì´í„°ëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì±„ìš°ê±°ë‚˜ ì–¸ì–´ì— íŠ¹í™”ëœ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤. \\n\\n- ë¡œì»¬ë¼ì´ì œì´ì…˜ í…ŒìŠ¤íŠ¸: LangsmithëŠ” ì‘ìš© í”„ë¡œê·¸ë¨ì„ ì—¬ëŸ¬ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ë¡œì»¬ë¼ì´ì œì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°œë°œìëŠ” ì‘ìš© í”„ë¡œê·¸ë¨ì´ ë‹¤ë¥¸ ì–¸ì–´ì—ì„œë„ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ê³  ì˜¬ë°”ë¥¸ ì–¸ì–´ë¡œ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n- ìì—°ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸: LangsmithëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP) í…ŒìŠ¤íŠ¸ì— ë„ì›€ì´ ë˜ëŠ” ë„êµ¬ì™€ ê¸°ëŠ¥ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°ì • ë¶„ì„, ë‹¨ì–´ì˜ ê³ ë¹ˆë„ ìˆ˜ ë˜ëŠ” ë¬¸ì¥ êµ¬ì¡° ë¶„ì„ê³¼ ê°™ì€ NLP ì‘ì—…ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” ê²ƒì„ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n- ì–¸ì–´ í…ŒìŠ¤íŠ¸ ìë™í™”: LangsmithëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìë™í™”í•˜ì—¬ ë°˜ë³µì ì¸ í…ŒìŠ¤íŠ¸ ì‘ì—…ì„ ê°€ì†í™”í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ê³ , í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë‹¤ë¥¸ ì–¸ì–´ ì„¤ì •ìœ¼ë¡œ ì‘ìš© í”„ë¡œê·¸ë¨ì„ êµ¬ì„±í•˜ëŠ” ë“± í…ŒìŠ¤íŠ¸ í™˜ê²½ì„ ì„¤ì •í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë¶„ì„: LangsmithëŠ” ì½”ë“œì˜ ì–¸ì–´ì  ì¸¡ë©´ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹ì • ì–¸ì–´ êµ¬ë¬¸ì´ë‚˜ ê¸°ëŠ¥ì´ í…ŒìŠ¤íŠ¸ì—ì„œ ì¶©ë¶„íˆ ì»¤ë²„ë¦¬ì§€ë¥¼ ë°›ëŠ”ì§€ í™•ì¸í•˜ì—¬ í…ŒìŠ¤íŠ¸ì˜ íš¨ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\n- ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤íŠ¸: ë‹¤êµ­ì–´ ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ LangsmithëŠ” ë²ˆì—­ì˜ ì •í™•ì„±ê³¼ ì¼ê´€ì„±ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°™ì€ ë¬¸ì¥ì´ ì—¬ëŸ¬ ì–¸ì–´ì—ì„œ ì¼ê´€ë˜ê²Œ ë²ˆì—­ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë“± ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n\\nìš”ì•½í•˜ë©´, LangsmithëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±, ë¡œì»¬ë¼ì´ì œì´ì…˜ í…ŒìŠ¤íŠ¸, ìì—°ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ì˜ ìë™í™” ë° íš¨ìœ¨í™”, í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë¶„ì„ ë“± ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ í™œë™ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ë„êµ¬ì™€ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°œì„ í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"input\": \"langsmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval Chain\n",
    "- ì§ˆë¬¸ì— ì œëŒ€ë¡œ ë‹µí•˜ë ¤ë©´ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. Retrievalì„ í†µí•´ ì´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "- Retrieval(ê²€ìƒ‰)ì€ LLMì— ì§ì ‘ ì „ë‹¬í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ë§ì€ ë°ì´í„°ê°€ ìˆì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤. \n",
    "- ê´€ë ¨ ë°ì´í„°ì—ì„œ Retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¶€ë¶„ë§Œ ê°€ì ¸ì™€ì„œ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬í•©ë‹ˆë‹¤. \n",
    "- ì•„ë˜ ì½”ë“œëŠ” ë²¡í„°ìŠ¤í† ì–´ì— ë°ì´í„°ë¥¼ ì €ì¥í•œ í›„, ì´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoupì„ ì„¤ì¹˜í•˜ê³ , WebBaseLoaderë¡œ ì›¹í˜ì´ì§€ ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„°ë¥¼ ì„ë² ë”©ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ë²¡í„°ìŠ¤í† ì–´ë¡œ ìƒ‰ì¸í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# FAISS(Fast Approximate Nearest Neighbor Search) ì„¤ì¹˜\n",
    "%pip install -qU faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Chain ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"ì œê³µëœ contextì—ë§Œ ê·¼ê±°í•˜ì—¬ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ì—¬ ì´í•´í•˜ê¸° ì‰½ê³  í•´ì„í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜í”„, ì°¨íŠ¸ ë˜ëŠ” ë‹¤ë¥¸ ì‹œê°ì  ìš”ì†Œë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì˜ ì¤‘ìš”ì„±ì„ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"LangSmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "    \"context\": [Document(page_content=\"LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmithëŠ” ê°œë°œìê°€ ë””ë²„ê¹…í•˜ê³ , í…ŒìŠ¤íŠ¸í•˜ê³ , í‰ê°€í•˜ê³ , ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ì™€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì²´ì¸(LLM frameworkë¡œ êµ¬ì¶•ë¨)ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ê²ƒì„ ë•ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ ì´ëŸ¬í•œ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” LangChainê³¼ ê°™ì€ ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì™€ ì›í™œí•˜ê²Œ í†µí•©í•˜ì—¬ ì‹ ì†í•˜ê²Œ ì‹¤í—˜í•˜ê³  ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ LangSmithëŠ” LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"LangSmithê°€ ì–´ë–»ê²Œ í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conversation Retrieval Chain\n",
    "- LLM ì£¼ìš” ì• í”Œë¦¬ì¼€ì´ì…˜ì¸ ì±„íŒ…ë´‡ êµ¬í˜„ì‹œì—ëŠ” ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- create_retrieval_chain í•¨ìˆ˜ ì‚¬ìš©ì‹œ 2ê°€ì§€ë¥¼ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "    - ê²€ìƒ‰ ë°©ë²•ì€ ì´ì œ ê°€ì¥ ìµœê·¼ì˜ ì…ë ¥ë§Œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.  \n",
    "    - ìµœì¢… LLM ì²´ì¸ë„ ë§ˆì°¬ê°€ì§€ë¡œ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Retrieval  \n",
    "- ê²€ìƒ‰ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ìƒˆ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.  \n",
    "- ì´ ì²´ì¸ì€ ê°€ì¥ ìµœê·¼ì˜ ì…ë ¥(input)ê³¼ ëŒ€í™” ê¸°ë¡(chat_history)ì„ ë°›ì•„ LLMì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í›„ì† ì§ˆë¬¸ì„ í•˜ì—¬ ì´ë¥¼ í…ŒìŠ¤íŠ¸í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'Introduction', 'language': 'en'})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"),\n",
    "    AIMessage(content=\"ì˜ˆ!\"),\n",
    "]\n",
    "\n",
    "retriever_chain.invoke({\"chat_history\": chat_history, \"input\": \"ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì´ë ‡ê²Œ í•˜ë©´ LangSmithì—ì„œ í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ ë¬¸ì„œê°€ ë°˜í™˜ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "- ì´ëŠ” LLMì´ ì±„íŒ… íˆìŠ¤í† ë¦¬ì™€ í›„ì† ì§ˆë¬¸ì„ ê²°í•©í•˜ì—¬ ìƒˆë¡œìš´ ì¿¼ë¦¬ë¥¼ ìƒì„±í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "- ì´ì œ ìƒˆë¡œìš´ retrieverê°€ ìƒê²¼ìœ¼ë‹ˆ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì—¼ë‘ì— ë‘ê³  ëŒ€í™”ë¥¼ ê³„ì†í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì²´ì¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End-to-endë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?'),\n",
       "  AIMessage(content='ì˜ˆ!')],\n",
       " 'input': 'ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.',\n",
       " 'context': [Document(page_content=\"LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'Introduction', 'language': 'en'})],\n",
       " 'answer': 'LangSmithëŠ” ê°œë°œìê°€ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒì„ ë•ëŠ” ë°ì— ì§‘ì¤‘í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì„ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: \\n\\n1. LangSmith ê³„ì • ë§Œë“¤ê¸°: LangSmithì˜ ê¸°ëŠ¥ë“¤ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¨¼ì € ê³„ì •ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. LangSmith í™ˆí˜ì´ì§€ì—ì„œ ì´ë©”ì¼ ì£¼ì†Œì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì—¬ ê³„ì •ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n2. LangSmith ì„¤ì •í•˜ê¸°: ê³„ì •ì´ ìƒì„±ë˜ë©´ LangSmithë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì„¤ì •ì—ëŠ” API í‚¤ ìƒì„±, í™˜ê²½ êµ¬ì„± ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. LangSmith ë¬¸ì„œì˜ \"ì„¤ì •\" ë¶€ë¶„ì—ì„œ ìì„¸í•œ ì§€ì¹¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n3. í…ŒìŠ¤íŠ¸í•  LLM ì‘ìš© í”„ë¡œê·¸ë¨ ì—…ë¡œë“œ: LangSmithë¡œ ì´ë™í•˜ì—¬ ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì½”ë“œë¥¼ ì—…ë¡œë“œí•˜ì‹­ì‹œì˜¤. LangSmithëŠ” LangChainì„ ë¹„ë¡¯í•˜ì—¬ ë‹¤ì–‘í•œ LLM frameworkì™€ í•¨ê»˜ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\n4. í‰ê°€ ì‹œì‘: ì½”ë“œë¥¼ ì—…ë¡œë“œí•œ í›„ì—ëŠ” LangSmithì˜ í‰ê°€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í‰ê°€ ê¸°ëŠ¥ì€ ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì •í™•ë„, ì„±ëŠ¥, í–‰ë™ ë“±ì„ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë‹¤ì–‘í•œ ë„êµ¬ì™€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\\n\\n5. ì¶”ì  ë° ëª¨ë‹ˆí„°ë§: ì‘ìš© í”„ë¡œê·¸ë¨ì˜ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ë‚œ í›„ì—ëŠ” LangSmithì˜ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì„¸ì…˜ì„ ì¶”ì í•˜ê³  ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì„±ëŠ¥ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  í•„ìš”í•œ ì¡°ì •ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n6. í‰ê°€ ê²°ê³¼ í™•ì¸: í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ë©´ LangSmithì—ì„œ ì œê³µë˜ëŠ” í‰ê°€ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LangSmithëŠ” ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì„±ëŠ¥ë¥¼ ì‹œê°í™”í•˜ê³  ë¶„ì„í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë‹¤ì–‘í•œ ë„êµ¬ì™€ ì°¨íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. \\n\\nì´ ì™¸ì—ë„ LangSmithëŠ” LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì „ì²´ì—ì„œ ë„ì›€ì´ ë˜ëŠ” ë§ì€ ê¸°ëŠ¥ê³¼ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê°œë°œìëŠ” LangSmith ë¬¸ì„œì˜ \"User Guide\" ì„¹ì…˜ì—ì„œ ìì„¸í•œ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"),\n",
    "    AIMessage(content=\"ì˜ˆ!\"),\n",
    "]\n",
    "\n",
    "retrieval_chain.invoke({\"chat_history\": chat_history, \"input\": \"ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent - OpenAI API Key í•„ìš”\n",
    "- AgentëŠ” LLMì´ ìˆ˜í–‰í•  ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "- Agentë¥¼ ë§Œë“¤ ë•Œ Agentê°€ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” ë„êµ¬(Tool)ì„ ì •í•©ë‹ˆë‹¤.\n",
    "- ì´ ì˜ˆì—ì„œëŠ” ì—ì´ì „íŠ¸ì—ê²Œ 2ê°œì˜ Toolì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ ê¶Œí•œì„ ë¶€ì—¬í•˜ê² ìŠµë‹ˆë‹¤:\n",
    "    1. ë°©ê¸ˆ ë§Œë“  Retriever : LangSmithì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€\n",
    "    2. ê²€ìƒ‰ ë„êµ¬(Search tool) : ìµœì‹  ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸ì— ë‹µë³€  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieverë¥¼ ìœ„í•œ íˆ´ì„ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tavily(Search ì—”ì§„) API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ \n",
    "- API Key - https://app.tavily.com/  \n",
    "- Command Prompt/Termial ì—ì„œ ì•„ë˜ ëª…ë ì–´ ì‹¤í–‰ : `Ctrl + ` \n",
    "    - Windows : setx  TAVILY_API_KEY=\"...\"\n",
    "    - macOS, Linux : export TAVILY_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"<your Tavily API key if not set as env var>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### ë¯¸ë¦¬ ì •ì˜ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ langchain hub ì„¤ì¹˜\n",
    " https://smith.langchain.com/hub/  \n",
    " https://smith.langchain.com/hub/hwchase17/openai-functions-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__b65e9f75a6b74a72ad48df022821e1ce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agentë¥¼ í˜¸ì¶œí•˜ê³  Agentì˜ ì‘ë‹µì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'How can LangSmith help with tests?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Startâ€‹Tracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Stepsâ€‹Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmithëŠ” í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì£¼ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ LLM(ì–¸ì–´ ëª¨ë¸) í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì²´ì¸ ë° ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¥¼ ë””ë²„ê¹…, í…ŒìŠ¤íŠ¸, í‰ê°€ ë° ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LangSmithëŠ” LangChainê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ë©°, LangChainì€ LLMê³¼ í•¨ê»˜ ì‘ì—…í•˜ê¸° ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ì˜ ê° ë‹¨ê³„ì—ì„œ ì§€ì›ë˜ëŠ” ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•´ ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì  ë° í‰ê°€ ê¸°ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LangSmithì˜ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmithê°€ í…ŒìŠ¤íŠ¸ì— ì–´ë–¤ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?',\n",
       " 'output': 'LangSmithëŠ” í…ŒìŠ¤íŠ¸ì— ë„ì›€ì„ ì£¼ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ LLM(ì–¸ì–´ ëª¨ë¸) í”„ë ˆì„ì›Œí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì²´ì¸ ë° ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¥¼ ë””ë²„ê¹…, í…ŒìŠ¤íŠ¸, í‰ê°€ ë° ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LangSmithëŠ” LangChainê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ë©°, LangChainì€ LLMê³¼ í•¨ê»˜ ì‘ì—…í•˜ê¸° ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ì˜ ê° ë‹¨ê³„ì—ì„œ ì§€ì›ë˜ëŠ” ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•´ ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì  ë° í‰ê°€ ê¸°ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LangSmithì˜ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"LangSmithê°€ í…ŒìŠ¤íŠ¸ì— ì–´ë–¤ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'ì„œìš¸ ë‚ ì”¨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.weather.go.kr/w/index.do', 'content': 'ê¸°ìƒì²­ ë‚ ì”¨ëˆ„ë¦¬ëŠ” ì „êµ­ì˜ ë‚ ì”¨ ì˜ˆë³´, íŠ¹ë³´, ê¸°í›„ì •ë³´, ëŒ€ê¸°ì§ˆ ì •ë³´ ë“±ì„ ì œê³µí•˜ëŠ” ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤. ì„œìš¸ ë‚ ì”¨ëŠ” í™ˆ í˜ì´ì§€ ìƒë‹¨ì˜ ë‚ ì”¨ ì•„ì´ì½˜ì„ í´ë¦­í•˜ë©´'}, {'url': 'https://www.weather.go.kr/w/weather/forecast/mid-term.do?stnId1=109', 'content': 'ì„œìš¸ã†ì¸ì²œã†ê²½ê¸°ë„. (ê°•ìˆ˜) 28ì¼ (ëª©)ì€ ë¹„ê°€ ë‚´ë¦¬ê² ìŠµë‹ˆë‹¤. (ê¸°ì˜¨) ì´ë²ˆ ì˜ˆë³´ê¸°ê°„ ì•„ì¹¨ ê¸°ì˜¨ì€ 1~9ë„, ë‚® ê¸°ì˜¨ì€ 12~20ë„ë¡œ í‰ë…„ (ìµœì €ê¸°ì˜¨ 0~6ë„, ìµœê³ ê¸°ì˜¨ 12~17ë„)ê³¼ ë¹„ìŠ·í•˜ê±°ë‚˜ ë†’ê² ìŠµë‹ˆë‹¤. (í•´ìƒ) ì„œí•´ì¤‘ë¶€í•´ìƒì˜ ë¬¼ê²°ì€ 0.5~2.0më¡œ ì¼ê² ìŠµë‹ˆë‹¤. (ì£¼ë§ì „ë§) 30ì¼ (í†  ...'}, {'url': 'https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081', 'content': 'ì„œìš¸ì‹œì˜ í˜„ì¬ ë‚ ì”¨ëŠ” êµ¬ë¦„ ì¡°ê¸ˆì´ê³  44Â°F, RealFeelÂ® 39Â°Fì…ë‹ˆë‹¤. ë°¤ì—ëŠ” íë¦¬ê³  ë‡Œìš° í™•ë¥ ì´ 40%ì´ë©°, ìµœì € ì˜¨ë„ëŠ” 32Â°Fì…ë‹ˆë‹¤.'}, {'url': 'https://weather.com/ko-KR/weather/today/l/82e46175f97c224acf6b95afc4934fbae0e4ba123adcee8a52b7be97c303467b', 'content': 'The Weather Channel ë° Weather.comì´ ì œê³µí•˜ëŠ” ì˜¤ëŠ˜ê³¼ ì˜¤ëŠ˜ ë°¤ ì„œìš¸íŠ¹ë³„ì‹œ ì¼ê¸°ì˜ˆë³´, ë‚ ì”¨ ìƒíƒœ ë° ë„í”ŒëŸ¬ ë ˆì´ë”'}, {'url': 'https://www.accuweather.com/ko/kr/seoul/226081/hourly-weather-forecast/226081', 'content': 'ì„œìš¸ì‹œì—ì„œ ì˜¤ëŠ˜ ì˜¤ì „ 7ì‹œë¶€í„° ì˜¤í›„ 11ì‹œê¹Œì§€ëŠ” ë¹„ê°€ ë‚´ë¦¬ê³  ìŠµë„ê°€ ë†’ê³  ëŒ€ê¸°ì§ˆì´ ë‚˜ì¨ì…ë‹ˆë‹¤. ì˜¤í›„ 11ì‹œë¶€í„°ëŠ” ë¹„ê°€ ë©ˆê³  êµ¬ë¦„ì´ ë®ì´ê³  ìµœê³  ê¸°ì˜¨ì€ 54ë„, ìµœì € ê¸°ì˜¨ì€ 43ë„ì…ë‹ˆë‹¤.'}]\u001b[0m\u001b[32;1m\u001b[1;3mì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” êµ¬ë¦„ì´ ì¡°ê¸ˆ ìˆê³  44Â°Fì´ë©° RealFeelÂ® ì˜¨ë„ëŠ” 39Â°Fì…ë‹ˆë‹¤. ë°¤ì—ëŠ” íë¦¬ê³  ë‡Œìš° í™•ë¥ ì´ 40%ì´ë©°, ìµœì € ì˜¨ë„ëŠ” 32Â°Fì…ë‹ˆë‹¤. ìì„¸í•œ ì •ë³´ëŠ” [AccuWeather](https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ”?',\n",
       " 'output': 'ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” êµ¬ë¦„ì´ ì¡°ê¸ˆ ìˆê³  44Â°Fì´ë©° RealFeelÂ® ì˜¨ë„ëŠ” 39Â°Fì…ë‹ˆë‹¤. ë°¤ì—ëŠ” íë¦¬ê³  ë‡Œìš° í™•ë¥ ì´ 40%ì´ë©°, ìµœì € ì˜¨ë„ëŠ” 32Â°Fì…ë‹ˆë‹¤. ìì„¸í•œ ì •ë³´ëŠ” [AccuWeather](https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'How can LangSmith help with LLM application testing?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookLangSmithOn this pageLangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Startâ€‹Tracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Stepsâ€‹Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmithëŠ” í”„ë¡œë•ì…˜ê¸‰ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ ì–´ë–¤ LLM í”„ë ˆì„ì›Œí¬ë¡œ êµ¬ì¶•ëœ ì²´ì¸ ë° ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¥¼ ë””ë²„ê¹…, í…ŒìŠ¤íŠ¸, í‰ê°€ ë° ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangSmithëŠ” LangChainê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ìˆìŠµë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LangSmithì˜ ì‚¬ìš©ì ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?'),\n",
       "  AIMessage(content='ì˜ˆ!')],\n",
       " 'input': 'ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.',\n",
       " 'output': 'LangSmithëŠ” í”„ë¡œë•ì…˜ê¸‰ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ë©´ ì–´ë–¤ LLM í”„ë ˆì„ì›Œí¬ë¡œ êµ¬ì¶•ëœ ì²´ì¸ ë° ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¥¼ ë””ë²„ê¹…, í…ŒìŠ¤íŠ¸, í‰ê°€ ë° ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ LangSmithëŠ” LangChainê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ ìˆìŠµë‹ˆë‹¤. LangSmithë¥¼ ì‚¬ìš©í•˜ì—¬ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ LangSmithì˜ ì‚¬ìš©ì ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(content=\"LangSmithê°€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸ë¥¼ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?\"),\n",
    "    AIMessage(content=\"ì˜ˆ!\"),\n",
    "]\n",
    "agent_executor.invoke({\"chat_history\": chat_history, \"input\": \"ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Serving with LangServe\n",
    "#### langserve, fastapië¥¼ ì„¤ì¹˜í•˜ê³  ë¡œì»¬ì‹œìŠ¤í…œ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "#### `py311\\Scripts\\activate`  ë˜ëŠ” `source py311/bin/activate` \n",
    "#### `cd code`        \n",
    "#### `python server.py`    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langserve fastapi sse_starlette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### server.py íŒŒì¼ì˜ ë‚´ìš©ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# from typing import List\n",
    "\n",
    "# from fastapi import FastAPI\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_community.embeddings import CohereEmbeddings\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# from langchain import hub\n",
    "# from langchain.agents import create_openai_functions_agent\n",
    "# from langchain.agents import AgentExecutor\n",
    "# from langchain.pydantic_v1 import BaseModel, Field\n",
    "# from langchain_core.messages import BaseMessage\n",
    "# from langserve import add_routes\n",
    "\n",
    "# # 1. Load Retriever\n",
    "# loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "# docs = loader.load()\n",
    "# text_splitter = RecursiveCharacterTextSplitter()\n",
    "# documents = text_splitter.split_documents(docs)\n",
    "# # embeddings = OpenAIEmbeddings()\n",
    "# embeddings = CohereEmbeddings()\n",
    "# vector = FAISS.from_documents(documents, embeddings)\n",
    "# retriever = vector.as_retriever()\n",
    "\n",
    "# # 2. Create Tools\n",
    "# retriever_tool = create_retriever_tool(\n",
    "#     retriever,\n",
    "#     \"langsmith_search\",\n",
    "#     \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    "# )\n",
    "# search = TavilySearchResults()\n",
    "# tools = [retriever_tool, search]\n",
    "\n",
    "\n",
    "# # 3. Create Agent\n",
    "# prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# # 4. App definition\n",
    "# app = FastAPI(\n",
    "#     title=\"LangChain Server\",\n",
    "#     version=\"1.0\",\n",
    "#     description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    "# )\n",
    "\n",
    "# # 5. Adding chain route\n",
    "\n",
    "# # We need to add these input/output schemas because the current AgentExecutor\n",
    "# # is lacking in schemas.\n",
    "\n",
    "\n",
    "# class Input(BaseModel):\n",
    "#     input: str\n",
    "#     chat_history: List[BaseMessage] = Field(\n",
    "#         ...,\n",
    "#         extra={\"widget\": {\"type\": \"chat\", \"input\": \"location\"}},\n",
    "#     )\n",
    "\n",
    "\n",
    "# class Output(BaseModel):\n",
    "#     output: str\n",
    "\n",
    "\n",
    "# add_routes(\n",
    "#     app,\n",
    "#     agent_executor.with_types(input_type=Input, output_type=Output),\n",
    "#     path=\"/agent\",\n",
    "# )\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import uvicorn\n",
    "\n",
    "#     uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playground\n",
    "- http://localhost:8000/agent/playground/ ì ‘ì†\n",
    "- Input : LangSmith ê°€ í…ŒìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'LangSmithëŠ” ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ê²€ìƒ‰ì„ í†µí•´ í•„ìš”í•œ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ë˜í•œ LangSmithë¥¼ í†µí•´ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì–»ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. LangSmithë¥¼ í™œìš©í•˜ì—¬ ì›í•˜ëŠ” ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ì°¾ì•„ë³´ì„¸ìš”!'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/agent/\")\n",
    "remote_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"LangSmith ê°€ í…ŒìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "        \"chat_history\": [],  # Providing an empty list as this is the first call\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
